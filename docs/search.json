[{"path":"https://jpcompartir.github.io/BertopicR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 BertopicR authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/articles/bertopic.html","id":"adjusting-model-parameters","dir":"Articles","previous_headings":"","what":"Adjusting Model Parameters","title":"Topic Modelling with Bertopic","text":"creating model, can alter min_topic_size arguments control number posts required per topic. can also specify ngram_range diversity parameters control size diversity ngrams used represent topics set stopwords TRUE prevent stopwords appearing representative ngrams (Note remove text analysed, ngrams used describe topics). also possible use nr_topics argument specify exact number topics like model output however done without careful examination data. run bt_fit_transform_model() function might noticed can get different results time run , due stochastic nature umap, avoid can specify random state prevents stochastic behaviour gives reproducible results. Reproducing results can also achieved saving model reusing , completely fine run model number times see topics output save model feel best fits research. already run bt_fit_transform_model() data, can simply feed already saved embedding model, time bt_fit_transform_model function output bertopic model, embeddings. Note: information hyperparameter tuning can found BERTopic website Lets look output topics time: time get 6 topics output much manageable analysis.","code":"model <- bt_fit_transform_model(cleaned_text = data$text_clean,                              calculated_embeddings = embeddings,                              min_topic_size = 30,                              ngram_range = c(1, 3),                              diversity = 0.5,                              stopwords = TRUE,                              random_state = 42) model$get_topic_info() #>   Topic Count #> 1    -1   170 #> 2     0  5235 #> 3     1   220 #> 4     2   123 #> 5     3    41 #>                                                                                      Name #> 1                                   -1_hispanic heritage_prepare_ellen ochoa_receive turn #> 2                                   0_heritage month_hispanic heritage month_day_students #> 3                                                              1_beto_heritage_fake_lacks #> 4 2_beto rourke_rourke membership lacks_membership lacks hispanic_hispanic caucus refuses #> 5                                         3_54th annual hispanic_5th ave____tradition 5th #>  [ reached 'max' / getOption(\"max.print\") -- omitted 1 rows ]"},{"path":"https://jpcompartir.github.io/BertopicR/articles/bertopic.html","id":"exploring-topics","dir":"Articles","previous_headings":"","what":"Exploring Topics","title":"Topic Modelling with Bertopic","text":"Now might need take closer look topic understand better . use bt_make_df() function merge bert results Sprinklr export. can look topics using ParseR create bigrams, BertopicR function bt_viz_top_terms() create top terms plot look exemplars filtering df topic ’re interested . Make bigrams:  Look top terms:   SegmentR, all_terms max_only plots returned can choose display charts bar lollipop viz pluck either all_terms max_only wish.  can also look diff_terms done using SegmentR:  want look exemplars can simply filter dataframe: can also look umap shows us topic distribution. can helpful showing us closely different topics relate one another continue check diagram merge topics reduce outliers. can use LandscapeR bertopic umap viz achieve . LandscapeR: BertopicR: key difference Bert LDA use hierarchical clustering, means can visualise cluster formed clusters might similar . can also look topic similarity heatmap see similar topics .","code":"merged_df <- data %>% bt_make_df(model = model,                              embeddings = embeddings,                              text_var = text_clean)  merged_df #> # A tibble: 5,829 × 61 #>    document universal_message_id                   social_network sender_user_id #>       <int> <chr>                                  <chr>          <chr>          #>  1        1 TWITTER_4_1057818026265980928          TWITTER        328184177      #>  2        2 TWITTER_2_1057782423700815873          TWITTER        2544249232     #>  3        3 TWITTER_2_1057758721747701762          TWITTER        227137623      #>  4        4 TWITTER_2_1057744985527910401          TWITTER        21702500       #>  5        5 TWITTER_2_1057730393053519873          TWITTER        1708113440     #>  6        6 INSTAGRAM_36_1902499764302394154_5416… INSTAGRAM      agriosmo       #>  7        7 TWITTER_2_1057716292281622528          TWITTER        7395452317968… #>  8        8 TWITTER_2_1057700738732908546          TWITTER        4258372295     #>  9        9 INSTAGRAM_36_1902419377766942925_7958… INSTAGRAM      tasteofstylec… #> 10       10 INSTAGRAM_36_1902389293970072552_1934… INSTAGRAM      salviqtpie84   #> # ℹ 5,819 more rows #> # ℹ 57 more variables: sender_screen_name <chr>, sender_listed_name <chr>, #> #   sender_profile_img_url <chr>, sender_profile_link <lgl>, #> #   sender_followers_count <dbl>, sender_influencer_score <lgl>, #> #   sender_age <lgl>, sender_gender <chr>, title <chr>, text_clean <chr>, #> #   message <chr>, message_type <chr>, created_time <date>, language <chr>, #> #   language_code <chr>, country_code <chr>, media_type_list <chr>, … merged_df %>% filter(topic == 4) %>%   ParseR::count_ngram(text_var = text_clean,                       remove_stops = TRUE,                       min_freq = 5,                       top_n = 25) %>%   purrr::pluck(\"viz\") %>%   ParseR::viz_ngram(emphasis = TRUE) #> Warning in max(node_freq): no non-missing arguments to max; returning -Inf #> Warning in min(node_freq): no non-missing arguments to min; returning Inf #> Warning in max(edge_freq): no non-missing arguments to max; returning -Inf #> Warning in min(edge_freq): no non-missing arguments to min; returning Inf merged_df %>%    bt_viz_top_terms(min_freq = 5,                 type = \"lollipop\")  #> $all_terms #>  #> $max_only merged_df %>%    bt_viz_top_terms(min_freq = 5,                 type = \"bars\") %>%   purrr::pluck(\"max_only\") merged_df %>%    bt_viz_diff_terms(min_freq = 5,                  type = \"lollipop\") %>%   purrr::pluck(\"topic0_vs_topic1\") merged_df %>%    filter(topic == 0) merged_df %>%    mutate(created_time = as.Date(created_time)) %>%   LandscapeR::conversation_landscape(id = document,                                      text_var = message,                                      colour_var = topic,                                      cleaned_text_var = text_clean,                                      date_var = created_time,                                      url_var = permalink,                                      sentiment_var = sentiment,                                      x_var = V1,                                      y_var = V2) model$visualize_documents(docs = data$text_clean,                            embeddings = embeddings)$show() model$visualize_hierarchy()$show() model$visualize_heatmap()$show()"},{"path":"https://jpcompartir.github.io/BertopicR/articles/bertopic.html","id":"refine-topics","dir":"Articles","previous_headings":"","what":"Refine Topics","title":"Topic Modelling with Bertopic","text":"Now better idea topic , maybe now like manually merge topics think might similar reduce size outlier category (-1). Merging topics performed outlier reduction. can see tree diagram visualise topic hierarchy topic 4 topic 0 branches cluster, looked individual documents bigrams apparent discuss hispanic heritage, might make sense merge . Make sure save model merging topics case unhappy result want revert back. Note: topics merge must given merge_topics function python list integers. convert r vector python list using r_to_py() function “L” suffix denote integer. unhappy new topics can always go back original model. need use “py$” suffix access libraries python environment. Now happy merged topics can look reducing “outliers”. important project, perhaps important get really high quality topics expense data maybe important include much data possible expense resolution. example going use “embeddings” strategy, lots different strategies can used can find : https://maartengr.github.io/BERTopic/getting_started/outlier_reduction/outlier_reduction.html#exploration order correctly reassign topics outliers need tell function document belongs topic, can use df output bt_make_df function, remember merged topics since generating df, need run update topics table. can play around threshold parameter adjust number reassigned documents, refers minimum similarity document topic reassigned topic correct value entirely dependent dataset specifications project. new topics, can update model reflect , , make sure save model updating case want return . TODO: flesh fully","code":"model$save(path = \"BertopicR_example.bt\") topics_to_merge <- r_to_py(c(0L,4L))  model$merge_topics(docs = data$text_clean,                    topics_to_merge = topics_to_merge)  model$get_topic_info() #>   Topic Count #> 1    -1   170 #> 2     0  5275 #> 3     1   220 #> 4     2   123 #> 5     3    41 #>                                                                                      Name #> 1                             -1_hispanic heritage_prepare_ellen ochoa_familys cyber cafe #> 2                                   0_heritage month_hispanic heritage month_day_students #> 3                                  1_trump_hispanic caucus_lacks hispanic heritage_warren #> 4 2_beto rourke_rourke membership lacks_membership lacks hispanic_hispanic caucus refuses #> 5                                            3_day parade_54th annual hispanic_5th ave___ model_og <- py$bertopic$BERTopic$load(path = \"BertopicR_example.bt\") merged_df <- data %>% bt_make_df(model = model,                               embeddings = embeddings,                              text_var = text_clean)  # redistribute topics new_topics <- model$reduce_outliers(documents = data$text_clean,                                      topics = merged_df$topic,                                     strategy=\"embeddings\",                                     threshold = 0.3) model$save(path = \"BERTopic_example.bt\") model$update_topics(docs = data$text_clean,                      topics = new_topics)"},{"path":"https://jpcompartir.github.io/BertopicR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jack Penzer. Maintainer, copyright holder. Aoife Ryan. Author.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ryan (2023). BertopicR: Wraps bertopic reticulate. R package version 0.0.0.9000, https://jpcompartir.github.io/BertopicR/.","code":"@Manual{,   title = {BertopicR: Wraps bertopic through reticulate},   author = {Aoife Ryan},   year = {2023},   note = {R package version 0.0.0.9000},   url = {https://jpcompartir.github.io/BertopicR/}, }"},{"path":"https://jpcompartir.github.io/BertopicR/index.html","id":"bertopicr","dir":"","previous_headings":"","what":"Wraps bertopic through reticulate","title":"Wraps bertopic through reticulate","text":"goal BertopicR allow R users access bertopic’s topic modelling suite R. package currently installs exact version bertopic - 0.14.0, make easier maintain package time prevent new users running install errors.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Wraps bertopic through reticulate","text":"installing bertopic make sure miniconda installed, don’t: reticulate miniconda installed, can install development version BertopicR GitHub : receive message: “bertopic installed packages current environment…” run:","code":"library(reticulate) #install.packages(\"reticulate\") if you don't have this already or aren't sure how to install.  reticulate::install_miniconda() # install.packages(\"devtools\") devtools::install_github(\"jpcompartir/BertopicR\")  library(BertopicR)  #Check your environment has been loaded correctly and bertopic has been installed: BertopicR::check_python_dependencies() BertopicR::install_python_dependencies()"},{"path":"https://jpcompartir.github.io/BertopicR/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Wraps bertopic through reticulate","text":"","code":"#TODO"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bert_example_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Example bert data — bert_example_data","title":"Example bert data — bert_example_data","text":"Sprinklr export used Microsoft Hispanic Heritage Month project.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bert_example_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example bert data — bert_example_data","text":"","code":"bert_example_data"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bert_example_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example bert data — bert_example_data","text":"data frame 6,019 observations 54 variables. Message Text variable, common variable SegmentR functions UniversalMessageId placeholder SenderUserId placeholder SenderListedName placeholder SenderProfileImgUrl placeholder SocialNetwork placeholder SenderScreenName placeholder SenderProfileLink placeholder Sender Followers Count placeholder SenderInfluencerScore placeholder SenderAge placeholder Title placeholder SenderGender placeholder MessageType placeholder CreatedTime placeholder Language placeholder LanguageCode placeholder CountryCode placeholder MediaTypeList placeholder Permalink placeholder Retweets placeholder Domain placeholder Tweet Generator placeholder Favorites placeholder ReceiverScreenName placeholder ReceiverId placeholder AssignedBy placeholder AssignedTo placeholder Spam placeholder Status placeholder Intel Location placeholder Intel Product placeholder Star Rating placeholder Priority placeholder Review Source placeholder Experience Score - Message level placeholder Sentiment placeholder ClientQueues placeholder PartnerQueues placeholder ClientCustomProps placeholder PartnerCustomProps placeholder Custom Tags placeholder Geo Target placeholder Action Time placeholder Post Id placeholder Associated Cases placeholder Location placeholder Country placeholder State placeholder City placeholder Longitude placeholder Latitude placeholder Message Type placeholder Sender Email placeholder","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_transform_model.html","id":null,"dir":"Reference","previous_headings":"","what":"fit a bertopic model to cleaned data — bt_fit_transform_model","title":"fit a bertopic model to cleaned data — bt_fit_transform_model","text":"fit bertopic model cleaned data","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_transform_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fit a bertopic model to cleaned data — bt_fit_transform_model","text":"","code":"bt_fit_transform_model( cleaned_text, calculated_embeddings = NULL, min_topic_size = 10, nr_topics = NULL, ngram_range = tuple(1,1), embedding_model = \"all-MiniLM-L6-v2\", accelerator = \"mps\", diversity = 0.1, stopwords = TRUE, random_state = NULL)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_transform_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fit a bertopic model to cleaned data — bt_fit_transform_model","text":"cleaned_text cleaned text column model fit calculated_embeddings embeddings already calculated input embeddings matrix min_topic_size minimum topic size nr_topics number topics find within dataset ngram_range ngram range topic representation embedding_model embedding model use used produce embeddings accelerator accelerator use - default mps, use NULL none diversity diversity topic representation (1 = diverse, 0 = diverse) stopwords whether remove stopwords topic representations random_state random state pass umap","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_transform_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"fit a bertopic model to cleaned data — bt_fit_transform_model","text":"list containing fitted bertopic model embeddings used fit model","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_df.html","id":null,"dir":"Reference","previous_headings":"","what":"make a df combining bertopic output with columns in original data export — bt_make_df","title":"make a df combining bertopic output with columns in original data export — bt_make_df","text":"make df combining bertopic output columns original data export","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make a df combining bertopic output with columns in original data export — bt_make_df","text":"","code":"bt_make_df( df, model, embeddings, text_var = message, date_var = created_time)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make a df combining bertopic output with columns in original data export — bt_make_df","text":"df original Sprinklr export topic modelling performed merge bertopic output model bertopic model embeddings embeddings used generate model text_var original, uncleaned text column, text used fit model date_var date column df corresponding text used fit model","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make a df combining bertopic output with columns in original data export — bt_make_df","text":"df bertopic output merged input columns sprinkr export","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_diff_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","title":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","text":"Function find terms greatest difference topics","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_diff_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","text":"","code":"bt_viz_diff_terms( merged_df, text_var = text_clean, topic_var = topic, stopwords = TRUE, hashtags = TRUE, mentions = TRUE, top_n = 15, min_freq = 25, include_outliers = FALSE, type = c(\"lollipops\", \"bars\") plots = list(c(1,2), c(4,5)))"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_diff_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","text":"merged_df output makedf function.Can df includes topic column text_var text diff_terms extracted topic_var column containing topic variable stopwords remove stopwords? hashtags remove hashtags? mentions remove mentions? top_n number terms extract min_freq minimum number times term appear considered include_outliers include outlier (-1) bertopic category? type lollipop bar chart plots specific plots output. input c(x, y) want 1 chart list(c(x, y), c(u, v)) x, y, u v topic numbers.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_diff_terms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","text":"ggplot object top different terms pair topics","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_top_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","title":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","text":"create top terms charts topic modelling completed using bertopic","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_top_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","text":"","code":"bt_viz_top_terms( merged_df, text_var = text_clean,  topic_var = topic, stopwords = TRUE, hashtags = TRUE, mentions = TRUE, top_n = 15, n_row = 2, min_freq = 25, include_outliers = FALSE, type = c(\"lollipops\", \"bars\"))"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_top_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","text":"merged_df df output makedf function.Can df includes topic column text_var text top terms extracted topic_var column containing topic variable stopwords remove (english) stopwords? hashtags remove hashtags? mentions remove mentions? top_n number terms extract n_row number rows plots take min_freq minimum number times term appear considered include_outliers include -1 (outlier) bertopic category type lollipop bar chart?","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_top_terms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","text":"list all_terms max_only top term bar charts","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/check_python_dependencies.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that dependencies are loaded — check_python_dependencies","title":"Check that dependencies are loaded — check_python_dependencies","text":"Check dependencies loaded","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/check_python_dependencies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that dependencies are loaded — check_python_dependencies","text":"","code":"check_python_dependencies()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/check_python_dependencies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that dependencies are loaded — check_python_dependencies","text":"message confirming whether dependencies loaded","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/install_python_dependencies.html","id":null,"dir":"Reference","previous_headings":"","what":"Install Python Dependencies — install_python_dependencies","title":"Install Python Dependencies — install_python_dependencies","text":"Install Python Dependencies","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/install_python_dependencies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install Python Dependencies — install_python_dependencies","text":"","code":"install_python_dependencies()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/install_python_dependencies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Install Python Dependencies — install_python_dependencies","text":"Nothing","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://jpcompartir.github.io/BertopicR/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""}]
