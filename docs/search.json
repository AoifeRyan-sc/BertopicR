[{"path":"https://jpcompartir.github.io/BertopicR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 BertopicR authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/articles/bertopic.html","id":"adjusting-model-parameters","dir":"Articles","previous_headings":"","what":"Adjusting Model Parameters","title":"Topic Modelling with Bertopic","text":"creating model, can alter min_topic_size arguments control number posts required per topic. can also specify ngram_range diversity parameters control size diversity ngrams used represent topics set stopwords TRUE prevent stopwords appearing representative ngrams (Note remove text analysed, ngrams used describe topics). also possible use nr_topics argument specify exact number topics like model output however done without careful examination data. run bt_fit_transform_model() function might noticed can get different results time run , due stochastic nature umap, avoid can specify random state prevents stochastic behaviour gives reproducible results. Reproducing results can also achieved saving model reusing , completely fine run model number times see topics output save model feel best fits research. already run bt_fit_transform_model() data, can simply feed already saved embedding model, time bt_fit_transform_model function output bertopic model, embeddings. Note: information hyperparameter tuning can found BERTopic website Lets look output topics time: time get 6 topics output much manageable analysis.","code":"model <- bt_fit_transform_model(cleaned_text = data$text_clean,                              calculated_embeddings = embeddings,                              min_topic_size = 30,                              ngram_range = c(1, 3),                              diversity = 0.5,                              stopwords = TRUE,                              random_state = 42) model$get_topic_info() #>   Topic Count #> 1    -1   170 #> 2     0  5235 #> 3     1   220 #> 4     2   123 #> 5     3    41 #>                                                                                      Name #> 1                                   -1_hispanic heritage_prepare_ellen ochoa_receive turn #> 2                                   0_heritage month_hispanic heritage month_day_students #> 3                                                              1_beto_heritage_fake_lacks #> 4 2_beto rourke_rourke membership lacks_membership lacks hispanic_hispanic caucus refuses #> 5                                         3_54th annual hispanic_5th ave____tradition 5th #>  [ reached 'max' / getOption(\"max.print\") -- omitted 1 rows ]"},{"path":"https://jpcompartir.github.io/BertopicR/articles/bertopic.html","id":"exploring-topics","dir":"Articles","previous_headings":"","what":"Exploring Topics","title":"Topic Modelling with Bertopic","text":"Now might need take closer look topic understand better . use bt_make_df() function merge bert results Sprinklr export. can look topics using ParseR create bigrams, BertopicR function bt_viz_top_terms() create top terms plot look exemplars filtering df topic ’re interested . Make bigrams:  Look top terms:   SegmentR, all_terms max_only plots returned can choose display charts bar lollipop viz pluck either all_terms max_only wish.  can also look diff_terms done using SegmentR:  want look exemplars can simply filter dataframe: can also look umap shows us topic distribution. can helpful showing us closely different topics relate one another continue check diagram merge topics reduce outliers. can use LandscapeR bertopic umap viz achieve . LandscapeR: BertopicR: key difference Bert LDA use hierarchical clustering, means can visualise cluster formed clusters might similar . can also look topic similarity heatmap see similar topics .","code":"merged_df <- data %>% bt_make_df(model = model,                              embeddings = embeddings,                              text_var = text_clean)  merged_df #> # A tibble: 5,829 × 61 #>    document universal_message_id                   social_network sender_user_id #>       <int> <chr>                                  <chr>          <chr>          #>  1        1 TWITTER_4_1057818026265980928          TWITTER        328184177      #>  2        2 TWITTER_2_1057782423700815873          TWITTER        2544249232     #>  3        3 TWITTER_2_1057758721747701762          TWITTER        227137623      #>  4        4 TWITTER_2_1057744985527910401          TWITTER        21702500       #>  5        5 TWITTER_2_1057730393053519873          TWITTER        1708113440     #>  6        6 INSTAGRAM_36_1902499764302394154_5416… INSTAGRAM      agriosmo       #>  7        7 TWITTER_2_1057716292281622528          TWITTER        7395452317968… #>  8        8 TWITTER_2_1057700738732908546          TWITTER        4258372295     #>  9        9 INSTAGRAM_36_1902419377766942925_7958… INSTAGRAM      tasteofstylec… #> 10       10 INSTAGRAM_36_1902389293970072552_1934… INSTAGRAM      salviqtpie84   #> # ℹ 5,819 more rows #> # ℹ 57 more variables: sender_screen_name <chr>, sender_listed_name <chr>, #> #   sender_profile_img_url <chr>, sender_profile_link <lgl>, #> #   sender_followers_count <dbl>, sender_influencer_score <lgl>, #> #   sender_age <lgl>, sender_gender <chr>, title <chr>, text_clean <chr>, #> #   message <chr>, message_type <chr>, created_time <date>, language <chr>, #> #   language_code <chr>, country_code <chr>, media_type_list <chr>, … merged_df %>% filter(topic == 4) %>%   ParseR::count_ngram(text_var = text_clean,                       remove_stops = TRUE,                       min_freq = 5,                       top_n = 25) %>%   purrr::pluck(\"viz\") %>%   ParseR::viz_ngram(emphasis = TRUE) #> Warning in max(node_freq): no non-missing arguments to max; returning -Inf #> Warning in min(node_freq): no non-missing arguments to min; returning Inf #> Warning in max(edge_freq): no non-missing arguments to max; returning -Inf #> Warning in min(edge_freq): no non-missing arguments to min; returning Inf merged_df %>%    bt_viz_top_terms(min_freq = 5,                 type = \"lollipop\")  #> $all_terms #>  #> $max_only merged_df %>%    bt_viz_top_terms(min_freq = 5,                 type = \"bars\") %>%   purrr::pluck(\"max_only\") merged_df %>%    bt_viz_diff_terms(min_freq = 5,                  type = \"lollipop\") %>%   purrr::pluck(\"topic0_vs_topic1\") merged_df %>%    filter(topic == 0) merged_df %>%    mutate(created_time = as.Date(created_time)) %>%   LandscapeR::conversation_landscape(id = document,                                      text_var = message,                                      colour_var = topic,                                      cleaned_text_var = text_clean,                                      date_var = created_time,                                      url_var = permalink,                                      sentiment_var = sentiment,                                      x_var = V1,                                      y_var = V2) model$visualize_documents(docs = data$text_clean,                            embeddings = embeddings)$show() model$visualize_hierarchy()$show() model$visualize_heatmap()$show()"},{"path":"https://jpcompartir.github.io/BertopicR/articles/bertopic.html","id":"refine-topics","dir":"Articles","previous_headings":"","what":"Refine Topics","title":"Topic Modelling with Bertopic","text":"Now better idea topic , maybe now like manually merge topics think might similar reduce size outlier category (-1). Merging topics performed outlier reduction. can see tree diagram visualise topic hierarchy topic 4 topic 0 branches cluster, looked individual documents bigrams apparent discuss hispanic heritage, might make sense merge . Make sure save model merging topics case unhappy result want revert back. Note: topics merge must given merge_topics function python list integers. convert r vector python list using r_to_py() function “L” suffix denote integer. unhappy new topics can always go back original model. need use “py$” suffix access libraries python environment. Now happy merged topics can look reducing “outliers”. important project, perhaps important get really high quality topics expense data maybe important include much data possible expense resolution. example going use “embeddings” strategy, lots different strategies can used can find : https://maartengr.github.io/BERTopic/getting_started/outlier_reduction/outlier_reduction.html#exploration order correctly reassign topics outliers need tell function document belongs topic, can use df output bt_make_df function, remember merged topics since generating df, need run update topics table. can play around threshold parameter adjust number reassigned documents, refers minimum similarity document topic reassigned topic correct value entirely dependent dataset specifications project. new topics, can update model reflect , , make sure save model updating case want return . TODO: flesh fully","code":"model$save(path = \"BertopicR_example.bt\") topics_to_merge <- r_to_py(c(0L,4L))  model$merge_topics(docs = data$text_clean,                    topics_to_merge = topics_to_merge)  model$get_topic_info() #>   Topic Count #> 1    -1   170 #> 2     0  5275 #> 3     1   220 #> 4     2   123 #> 5     3    41 #>                                                                                      Name #> 1                             -1_hispanic heritage_prepare_ellen ochoa_familys cyber cafe #> 2                                   0_heritage month_hispanic heritage month_day_students #> 3                                  1_trump_hispanic caucus_lacks hispanic heritage_warren #> 4 2_beto rourke_rourke membership lacks_membership lacks hispanic_hispanic caucus refuses #> 5                                            3_day parade_54th annual hispanic_5th ave___ model_og <- py$bertopic$BERTopic$load(path = \"BertopicR_example.bt\") merged_df <- data %>% bt_make_df(model = model,                               embeddings = embeddings,                              text_var = text_clean)  # redistribute topics new_topics <- model$reduce_outliers(documents = data$text_clean,                                      topics = merged_df$topic,                                     strategy=\"embeddings\",                                     threshold = 0.3) model$save(path = \"BERTopic_example.bt\") model$update_topics(docs = data$text_clean,                      topics = new_topics)"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"modules","dir":"Articles","previous_headings":"","what":"Modules","title":"Interacting with individaul modules","text":"Bertopic Python Library Maarten Grootendorst 6 sub-modules: Embeddings - transforming documents numerical representation Dimensionality Reduction - reducing number features embeddings output Clustering - finding groups similar documents represent topics Vectorisers - find n-grams describe topic c-TF-IDF - create topic-level (rather document) bag words matrices representing topics Fine-tuning topic representations - tools topic representations (includes generative AI/LLMs) vignette show use {BertopicR} tune module creating topic models.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"data","dir":"Articles","previous_headings":"Modules","what":"Data","title":"Interacting with individaul modules","text":"demonstrative purposes, ’ll use {stringr}‘s ’sentences’ data set, comes fairly clean. help cleaning text data visit ParseR/LimpiaR documentation. Let’s take look first five posts brevity. ’ll turn sentences data frame:","code":"sentences <- stringr::sentences sentences[1:5] #> [1] \"The birch canoe slid on the smooth planks.\"  #> [2] \"Glue the sheet to the dark blue background.\" #> [3] \"It's easy to tell the depth of a well.\"      #> [4] \"These days a chicken leg is a rare dish.\"    #> [5] \"Rice is often served in round bowls.\" df <- dplyr::tibble(sentences = tolower(sentences))"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"embeddings","dir":"Articles","previous_headings":"Modules","what":"Embeddings","title":"Interacting with individaul modules","text":"order work efficiently text data, need turn words numbers. current state---art approach turning text numbers, contextualised word embeddings. ’ll use MpNet model, ‘-mpnet-base-v2’ take sentences turn numbers (embeddings). allow us find similarities differences sentences, using standard mathematical techniques (don’t worry isn’t making sense right now, often best way learn ). BertopicR usually either want making modules, , compiling fitting models. make components, actions data components. compile components models, fit models data.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"make-the-embedder","dir":"Articles","previous_headings":"Modules > Embeddings","what":"Make the embedder","title":"Interacting with individaul modules","text":"First ’ll make embedder (embedding_model) using bt_make_embedder function. ’ll embed sentences using embedder. TIP: ’s good idea save embeddings, working many documents process time consuming.","code":"embedder <- bt_make_embedder(   model_name = \"all-mpnet-base-v2\"   )"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"do-the-embedding","dir":"Articles","previous_headings":"Modules > Embeddings","what":"Do the embedding","title":"Interacting with individaul modules","text":"row embeddings output represents one original sentences, column represents different embedding dimension; 768 dimensions outputted ‘-mpnet-base-v2’ mode take peek first 10 columns (dimensions), first row embeddings see 10 floating point numbers.","code":"embeddings <- bt_do_embedding(   embedder,    df$sentences   ) #>  #> Embedding proccess finished #> all-mpnet-base-v2 added to embeddings attributes  embeddings[1, 1:10] #>  [1]  0.0031732298 -0.0454455912 -0.0003524604  0.0046989545  0.0179691706 #>  [6] -0.0300240200 -0.0278541446 -0.0199615490 -0.0032402189  0.0257827919"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"reducing-dimensions","dir":"Articles","previous_headings":"Modules","what":"Reducing Dimensions","title":"Interacting with individaul modules","text":"next step pipeline reduce dimensions embeddings, two reasons: bertopic pipeline perform dimensionality reduction two reasons allow clustering algorithm run smoothly visualise clusters plane (eventually reduce 2 dimensions) machine learning generally, dimensionality reduction often important step avoid overfitting curse dimensionality. information UMAP algorithm - uniform manifold approximation projection dimension reduction - catchy, see UMAP Docs. TIP: Like embeddings, ’s good idea save reduced embeddings, reducing dimensions can costly process.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"make-the-reducer","dir":"Articles","previous_headings":"Modules > Reducing Dimensions","what":"Make the reducer","title":"Interacting with individaul modules","text":"’ll use low-ish value n_neighbours (small dataset) output 5 dimensions (n_components = 5L). ’ll set min_distance 0, dimensionality reduction model can place similar documents close together. ’ll set metric “Euclidean” see Embedding non-Euclidean Spaces alternatives.","code":"reducer <- bt_make_reducer(   n_neighbors = 10L,    n_components = 10L,   min_dist = 0L,   metric = \"euclidean\"   )"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"do-the-reducing","dir":"Articles","previous_headings":"Modules > Reducing Dimensions","what":"Do the reducing","title":"Interacting with individaul modules","text":"’ll take peek two rows now represent reduced dimension embeddings document. Notice numbers floating points, also bounded -1 1. next step cluster data. first pass, bertopic considers discovered cluster topic. Choice clustering model selected parameters therefore important. ’ll use hdbscan cluster, ’s bertopic initially built .","code":"reduced_embeddings <- bt_do_reducing(   reducer, embeddings = embeddings )  reduced_embeddings[1:2, ] #>          [,1]     [,2]     [,3]     [,4]      [,5]     [,6]     [,7]     [,8] #> [1,] 5.577491 4.748748 8.720358 4.652689 1.1635658 7.434086 6.954169 2.831987 #> [2,] 4.362792 5.198727 6.913936 4.265765 0.1532703 7.678880 6.424238 1.552353 #>          [,9]    [,10] #> [1,] 3.995395 2.318015 #> [2,] 4.829968 2.881720"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"clustering","dir":"Articles","previous_headings":"Modules","what":"Clustering","title":"Interacting with individaul modules","text":"lot learn comes clustering, selecting correct parameters notoriously difficult - especially clustering without pre-assigned labels, clustering tends . run ’ll use hdbscan clustering algorithm, don’t know many clusters look advance (using kMeans clustering exampel).hdbscan documentation ’s important know get level updating topic representations, bertopic pipeline 1 topic = 1 cluster. ’s therefore crucial gather information can data inform clustering process.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"make-the-clusterer","dir":"Articles","previous_headings":"Modules > Clustering","what":"Make the clusterer","title":"Interacting with individaul modules","text":"’ll stick Euclidean distance metric, ’ll reduce min_cluster_size 10, giving us theoretical maximum number clusters : length(sentences) / 10 min_samples equal 5. relationship min_cluster_size min_samples important, default min_samples = min_cluster_size specified, likely adverse effects clustering outputs dealing larger datasets (’ll likely want raise min_cluster_size parameter significantly). hand, hdbscan documentation claims min_samples, parameter inherited dbscan, importance hdbscan algorithm - though also say remains algorithm’s biggest weakness. ’ll also set cluster_selection_method = “leaf”, means ’ll tend find many small clusters, rather large clusters. another parameter fraught danger, get right first time unlikely, likely require trial error, least beginning.","code":"clusterer <- bt_make_clusterer_hdbscan(min_cluster_size = 5L,                           metric = \"euclidean\",                           cluster_selection_method = \"leaf\",                           min_samples = 3L)"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"do-the-clustering","dir":"Articles","previous_headings":"Modules > Clustering","what":"Do the clustering","title":"Interacting with individaul modules","text":"clusters now list cluster labels, 720 labels total - one sentence {Stringr}’s sentences data set. cluster labels output integers, ’s important assume work like regular integers . ’s necessarily case cluster 1 closer cluster 4 cluster 15, ordering labels can effectively considered random. likely labels training/test/validation data set, rely inspecting clusters, remembering bertopic 1 cluster = 1 topic. check whether clusters make sense, draw upon data analysis & visualisation tool kit, inspect cluster every . soon become intractable. Instead, ’ll take quick look distribution ’ll use bt_compile_model() bt_fit_model() functions get topic models .","code":"clusters <- bt_do_clustering(clustering_model = clusterer, embeddings = reduced_embeddings)"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"create-a-data-frame","dir":"Articles","previous_headings":"Modules > Clustering","what":"Create a data frame","title":"Interacting with individaul modules","text":"first, ’re beginning acquire bunch objects may become hard maintain. can store data frame: want save data frame, ’ll need save .Rdata/.rds object, .csv .xlsx contains list columns.","code":"data <- dplyr::tibble(sentence = tolower(sentences)) %>%   mutate(embeddings = list(embeddings),          reduced_embeddings = list(reduced_embeddings),          cluster = as.integer(clusters))"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"count-the-clusters","dir":"Articles","previous_headings":"Modules > Clustering","what":"Count the clusters","title":"Interacting with individaul modules","text":"can see distribution via histogram:  can see clusters highest number posts: 177/720 (24.6%) data points labelled noise (cluster == -1), upon first inspection appear quite eclectic. clusters look? largest cluster, noise cluster, cluster 40. However, clusters look , difficult become figure ’s happening… Precious things, things shine? Wind, air? Inspecting clusters trying figure cluster means inter-relate soon become intractable humans. Thankfully, within BERTopic quantitative methods already place aid procedure. ’ll make vectoriser ctfidf model, ’ll compile model, fit model data, finally ’ll explore topics representations. vectoriser ’ll set ngram range c(1, 2) means topics can represented single words bigrams. ’ll set stop_words ‘english’ English stop words removed ’ll tell vectoriser consider words frequency 3 higher, rare words chance occurrences don’t clog representations much. practice, want set higher value min_frequency ’ll working significantly data. ’ll create ctfidf model allow us represent topic according words important topic (high frequency) distinct topic (relatively low frequency topics):","code":"library(ggplot2)  data %>%   filter(cluster != -1) %>%   count(cluster, sort = TRUE) %>%   ggplot(aes(x= n)) +   geom_histogram(fill = \"midnightblue\", bins = 20) +   theme_minimal() data %>%   count(cluster, sort = TRUE) #> # A tibble: 59 × 2 #>    cluster     n #>      <int> <int> #>  1      -1   177 #>  2      40    39 #>  3      23    20 #>  4      13    19 #>  5      11    16 #>  6      33    15 #>  7      47    15 #>  8      41    14 #>  9       4    13 #> 10      20    13 #> # ℹ 49 more rows data %>%   filter(cluster == -1) %>%    slice(30:40) %>%   pull(sentence) #>  [1] \"weave the carpet on the right hand side.\"         #>  [2] \"the harder he tried the less he got done.\"        #>  [3] \"a cramp is no small danger on a swim.\"            #>  [4] \"pluck the bright rose without leaves.\"            #>  [5] \"the glow deepened in the eyes of the sweet girl.\" #>  [6] \"bring your problems to the wise chief.\"           #>  [7] \"write a fond note to the friend you cherish.\"     #>  [8] \"clothes and lodging are free to new men.\"         #>  [9] \"the young kid jumped the rusty gate.\"             #> [10] \"a salt pickle tastes fine with ham.\"              #> [11] \"pure bred poodles have curls.\" data %>%   filter(cluster == 40) %>%   head(10) %>%    pull(sentence) #>  [1] \"kick the ball straight and follow through.\"     #>  [2] \"press the pants and sew a button on the vest.\"  #>  [3] \"hoist the load to your left shoulder.\"          #>  [4] \"open the crate but don't break the glass.\"      #>  [5] \"split the log with a quick, sharp blow.\"        #>  [6] \"the empty flask stood on the tin tray.\"         #>  [7] \"do that with a wooden stick.\"                   #>  [8] \"slash the gold cloth into fine ribbons.\"        #>  [9] \"cut the cord that binds the box tightly.\"       #> [10] \"a ridge on a smooth surface is a bump or flaw.\" data %>%   filter(cluster == 23) %>%   head(10) %>%   pull(sentence) #>  [1] \"the pearl was worn in a thin silver ring.\"       #>  [2] \"a tusk is used to make costly gifts.\"            #>  [3] \"she sewed the torn coat quite neatly.\"           #>  [4] \"she has a smart way of wearing clothes.\"         #>  [5] \"the gold ring fits only a pierced ear.\"          #>  [6] \"the store walls were lined with colored frocks.\" #>  [7] \"a gem in the rough needs work to polish.\"        #>  [8] \"brass rings are sold by these natives.\"          #>  [9] \"a sash of gold silk will trim her dress.\"        #> [10] \"fake stones shine but cost little.\" data %>%   filter(cluster ==13) %>%   head(10) %>%   pull(sentence) #>  [1] \"a wisp of cloud hung in the blue air.\"             #>  [2] \"the pennant waved when the wind blew.\"             #>  [3] \"those thistles bend in a high wind.\"               #>  [4] \"the tree top waved in a graceful way.\"             #>  [5] \"at that high level the air is pure.\"               #>  [6] \"a blue crane is a tall wading bird.\"               #>  [7] \"the fly made its way along the wall.\"              #>  [8] \"pink clouds floated with the breeze.\"              #>  [9] \"the vane on top of the pole revolved in the wind.\" #> [10] \"a chink in the wall allowed a draft to blow.\" vectoriser <- bt_make_vectoriser(ngram_range = c(1, 2), stop_words = \"english\", min_frequency = 3L) ctfidf <- bt_make_ctfidf(reduce_frequent_words = TRUE, bm25_weighting = FALSE)"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"compile-the-model","dir":"Articles","previous_headings":"Modules","what":"Compile the model","title":"Interacting with individaul modules","text":"’ve already made individual components, modules, selected parameters. ’ve already performed embeddings dimensionality reduction, bertopic allows us skip steps easily (can also skip clustering, won’t task adds extra complexity) - ’ll feed empty models bt_compile_model function embedding reducing. N.B. practice need pause explore parameters depth.","code":"topic_model <- bt_compile_model(   embedding_model = bt_base_embedder(),   reduction_model = bt_base_reducer(),   clustering_model = clusterer,   vectoriser_model = vectoriser,   ctfidf_model = ctfidf ) #>  #> Model built"},{"path":"https://jpcompartir.github.io/BertopicR/articles/modular_approach.html","id":"fit-the-model","dir":"Articles","previous_headings":"Modules","what":"Fit the model","title":"Interacting with individaul modules","text":"feed reduced embeddings rather original embeddings, allows us skip steps workflow; can save us lot time, particularly many documents. can create look table join sentences topic labels topic descriptions:","code":"fitted_model <- bt_fit_model(topic_model, data$sentence, embeddings = reduced_embeddings) topic_representations <- fitted_model$get_topic_info() topic_rep_lookup <- topic_representations %>%   select(topic = Topic, description = Name)  data <- data %>%   mutate(topic = fitted_model$topics_) %>%   left_join(topic_rep_lookup) #> Joining with `by = join_by(topic)`  (data <- data %>%    relocate(sentence, topic, description) ) #> # A tibble: 720 × 6 #>    sentence              topic description embeddings reduced_embeddings cluster #>    <chr>                 <dbl> <chr>       <list>     <list>               <int> #>  1 the birch canoe slid…    -1 -1_night_t… <dbl[…]>   <dbl [720 × 10]>        -1 #>  2 glue the sheet to th…    15 15_pencil_… <dbl[…]>   <dbl [720 × 10]>        27 #>  3 it's easy to tell th…    -1 -1_night_t… <dbl[…]>   <dbl [720 × 10]>        -1 #>  4 these days a chicken…    26 26_rare_se… <dbl[…]>   <dbl [720 × 10]>        14 #>  5 rice is often served…    26 26_rare_se… <dbl[…]>   <dbl [720 × 10]>        14 #>  6 the juice of lemons …    12 12_cut_tre… <dbl[…]>   <dbl [720 × 10]>        16 #>  7 the box was thrown b…    57 57_box_squ… <dbl[…]>   <dbl [720 × 10]>        26 #>  8 the hogs were fed ch…     9 9_spring_t… <dbl[…]>   <dbl [720 × 10]>         4 #>  9 four hours of steady…    -1 -1_night_t… <dbl[…]>   <dbl [720 × 10]>        -1 #> 10 a large size in stoc…    -1 -1_night_t… <dbl[…]>   <dbl [720 × 10]>        -1 #> # ℹ 710 more rows"},{"path":"https://jpcompartir.github.io/BertopicR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jack Penzer. Maintainer. Aoife Ryan. Author.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ryan (2023). BertopicR: Wraps bertopic reticulate. R package version 0.0.0.9000, https://jpcompartir.github.io/BertopicR/.","code":"@Manual{,   title = {BertopicR: Wraps bertopic through reticulate},   author = {Aoife Ryan},   year = {2023},   note = {R package version 0.0.0.9000},   url = {https://jpcompartir.github.io/BertopicR/}, }"},{"path":"https://jpcompartir.github.io/BertopicR/index.html","id":"bertopicr","dir":"","previous_headings":"","what":"Wraps bertopic through reticulate","title":"Wraps bertopic through reticulate","text":"goal BertopicR allow R users access bertopic’s topic modelling suite R. package aim implement every feature bertopic, designed specific end users mind may experienced programmers developers. may submit issues feature requests; however, may faster go direct original, Python library excellent documentation. [BERTopic documentation] package currently installs exact version bertopic - 0.15.0, features introduced version take time , may never, reach package.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Wraps bertopic through reticulate","text":"installing bertopic make sure miniconda installed, don’t: reticulate miniconda installed, can install development version BertopicR GitHub : receive message: “bertopic installed packages current environment…” run:","code":"library(reticulate) #install.packages(\"reticulate\") if you don't have this already or aren't sure how to install.  reticulate::install_miniconda() # install.packages(\"devtools\") devtools::install_github(\"jpcompartir/BertopicR\")  library(BertopicR)  #Check your environment has been loaded correctly and bertopic has been installed: BertopicR::check_python_dependencies() BertopicR::install_python_dependencies()"},{"path":"https://jpcompartir.github.io/BertopicR/index.html","id":"quickstart","dir":"","previous_headings":"","what":"Quickstart","title":"Wraps bertopic through reticulate","text":"BertopicR ships dataset unstructured text data bert_example_data","code":"data <- BertopicR::bert_example_data  embedder <- bt_make_embedder(\"all-minilm-l6-v2\") embeddings <- bt_do_embedding(embedder, documents = data$message,  batch_size = 16L) #>  #> Embedding proccess finished #> all-minilm-l6-v2 added to embeddings attributes   reducer <- bt_make_reducer(n_neighbors = 10L, n_components = 10L, metric = \"cosine\") clusterer <- bt_make_clusterer_hdbscan(min_cluster_size = 20L, metric = \"euclidean\", cluster_selection_method = \"eom\", min_samples = 10L)  topic_model <- bt_compile_model(embedding_model = embedder,                                 reduction_model = reducer,                                 clustering_model = clusterer) #>  #> No vectorising model provided, creating model with default parameters #>  #> No ctfidf model provided, creating model with default parameters #>  #> Model built  #Fit the model fitted_model <- bt_fit_model(model = topic_model,                               documents = data$message,                               embeddings = embeddings)  fitted_model$get_topic_info() %>%   dplyr::tibble() #> # A tibble: 34 × 3 #>    Topic Count Name                                                  #>    <dbl> <dbl> <chr>                                                 #>  1    -1  1760 -1_music_honor_amazing_spanish                        #>  2     0   197 0_celebrates_month celebration_october_heritage month #>  3     1   185 1_heritage night_festival_night_heritage celebration  #>  4     2   177 2_teachers_grade_students_parents                     #>  5     3   170 3_white_black_like_really                             #>  6     4   130 4_world_going_latina_got                              #>  7     5   125 5_awesome_yes_love_cool                               #>  8     6   119 6_utsw_hispanics_hispanicheritage_news                #>  9     7   108 7_latinx_latina_ll_chance                             #> 10     8    96 8_honored_community_honor_hosting                     #> # ℹ 24 more rows"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bert_example_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Example bert data — bert_example_data","title":"Example bert data — bert_example_data","text":"Example text data frame old social media API","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bert_example_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example bert data — bert_example_data","text":"","code":"bert_example_data"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bert_example_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example bert data — bert_example_data","text":"data frame 4,035 rows 1 column message Text variable, common variable SegmentR functions","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bertopic_detach.html","id":null,"dir":"Reference","previous_headings":"","what":"Detach bertopic from the python session — bertopic_detach","title":"Detach bertopic from the python session — bertopic_detach","text":"Call finished topic modelling process. Although, safer may simply save work restart R session, Python session still running (far know, way safely close)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bertopic_detach.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detach bertopic from the python session — bertopic_detach","text":"","code":"bertopic_detach()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bertopic_detach.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detach bertopic from the python session — bertopic_detach","text":"Nothing","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_clusterer.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a base clusterer for skipping clustering step of bertopic pipeline — bt_base_clusterer","title":"Create a base clusterer for skipping clustering step of bertopic pipeline — bt_base_clusterer","text":"Create base clusterer skipping clustering step bertopic pipeline","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_clusterer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a base clusterer for skipping clustering step of bertopic pipeline — bt_base_clusterer","text":"","code":"bt_base_clusterer()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_clusterer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a base clusterer for skipping clustering step of bertopic pipeline — bt_base_clusterer","text":"empty clustering model (Python class)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_clusterer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a base clusterer for skipping clustering step of bertopic pipeline — bt_base_clusterer","text":"","code":"base_clusterer <- bt_base_clusterer()  clusterer <- bt_base_clusterer()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_embedder.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a base embedder for skipping embedding step of bertopic pipeline — bt_base_embedder","title":"Create a base embedder for skipping embedding step of bertopic pipeline — bt_base_embedder","text":"Create base embedder skipping embedding step bertopic pipeline","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_embedder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a base embedder for skipping embedding step of bertopic pipeline — bt_base_embedder","text":"","code":"bt_base_embedder()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_embedder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a base embedder for skipping embedding step of bertopic pipeline — bt_base_embedder","text":"empty embedding model (Python class)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_embedder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a base embedder for skipping embedding step of bertopic pipeline — bt_base_embedder","text":"","code":"base_emebdder <- bt_base_embedder()  embedder <- bt_base_embedder()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_reducer.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a base reducer for skipping dimensionality reduction step of bertopic pipeline — bt_base_reducer","title":"Create a base reducer for skipping dimensionality reduction step of bertopic pipeline — bt_base_reducer","text":"Create base reducer skipping dimensionality reduction step bertopic pipeline","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_reducer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a base reducer for skipping dimensionality reduction step of bertopic pipeline — bt_base_reducer","text":"","code":"bt_base_reducer()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_reducer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a base reducer for skipping dimensionality reduction step of bertopic pipeline — bt_base_reducer","text":"empty dimensionality reduction model (Python class)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_base_reducer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a base reducer for skipping dimensionality reduction step of bertopic pipeline — bt_base_reducer","text":"","code":"base_reducer <- bt_base_reducer()  reducer <- bt_base_reducer()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_compile_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a BERTopic model — bt_compile_model","title":"Build a BERTopic model — bt_compile_model","text":"Keep *_model = NULL proceed model made default parameters (see individual make_* function parameters). However, advisable accept default parameters model; tune model according dataset business question answering.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_compile_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a BERTopic model — bt_compile_model","text":"","code":"bt_compile_model(   embedding_model = NULL,   reduction_model = NULL,   clustering_model = NULL,   vectoriser_model = NULL,   ctfidf_model = NULL )"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_compile_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a BERTopic model — bt_compile_model","text":"embedding_model Model creating embeddings (Python object) reduction_model Model reducing embeddings' dimensions (Python object) clustering_model Model clustering (Python object) vectoriser_model Model vectorising input topic representations (Python object) ctfidf_model Model performing class-based tf-idf (ctf-idf) (Python object)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_compile_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a BERTopic model — bt_compile_model","text":"BERTopic model","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_clustering.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster your data — bt_do_clustering","title":"Cluster your data — bt_do_clustering","text":"Cluster data","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_clustering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster your data — bt_do_clustering","text":"","code":"bt_do_clustering(clustering_model, embeddings)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_clustering.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster your data — bt_do_clustering","text":"clustering_model Python object, output bt_make_clusterer* embeddings Embeddings, output bt_do_embedding bt_do_reducing","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_clustering.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster your data — bt_do_clustering","text":"Cluster labels document","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_embedding.html","id":null,"dir":"Reference","previous_headings":"","what":"Embed your documents — bt_do_embedding","title":"Embed your documents — bt_do_embedding","text":"Takes document, list documents, returns numerical embedding can used features machine learning model semantic similarity search. pre-computed embeddings can skip step. bt_embed function designed used one step topic modelling pipeline.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_embedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embed your documents — bt_do_embedding","text":"","code":"bt_do_embedding(   embedder,   documents,   ...,   accelerator = \"mps\",   progress_bar = TRUE )"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_embedding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embed your documents — bt_do_embedding","text":"embedder embedding model (output bt_make_embedder) documents character vector documents embedded, e.g. text variable ... Optional additional parameters passed SentenceTransformer's encode function, e.g. batch_size accelerator string containing name hardware accelerator, e.g. \"mps\", \"cuda\". NULL acceleartor used. progress_bar logical value indicating whether progress bar shown console","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_embedding.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Embed your documents — bt_do_embedding","text":"array floating point numbers","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_embedding.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Embed your documents — bt_do_embedding","text":"Initially function built upon sentence_transformers Python library, may expanded accept frameworks. feed documents list. can use hardware accelerators e.g. GPUs, speed computation. function currently returns object two additional attributes: embedding_model, n_documents, appended embeddings extraction later steps pipeline, e.g. merging data frames later important check many documents entered.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_reducing.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform dimensionality reduction on your embeddings — bt_do_reducing","title":"Perform dimensionality reduction on your embeddings — bt_do_reducing","text":"Perform dimensionality reduction embeddings","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_reducing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform dimensionality reduction on your embeddings — bt_do_reducing","text":"","code":"bt_do_reducing(reducer, embeddings)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_reducing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform dimensionality reduction on your embeddings — bt_do_reducing","text":"reducer dimensionality reduction model embeddings embeddings","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_do_reducing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform dimensionality reduction on your embeddings — bt_do_reducing","text":"Embeddingd reduced number dimensions","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a topic model on your documents & embeddings — bt_fit_model","title":"Fit a topic model on your documents & embeddings — bt_fit_model","text":"already performed dimensionality reduction embeddings, can feed reduced dimension embeddings embeddings argument, make sure supply bt_compile_model base reducer (output bt_base_reducer())","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a topic model on your documents & embeddings — bt_fit_model","text":"","code":"bt_fit_model(model, documents, embeddings, topic_labels = NULL)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a topic model on your documents & embeddings — bt_fit_model","text":"model Output bt_compile_model() another bertopic topic model documents documents topic model embeddings embeddings, can reduced dimensionality topic_labels Pre-existing labels, supervised topic modelling","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a topic model on your documents & embeddings — bt_fit_model","text":"fitted BERTopic model","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_transform_model.html","id":null,"dir":"Reference","previous_headings":"","what":"fit a bertopic model to cleaned data — bt_fit_transform_model","title":"fit a bertopic model to cleaned data — bt_fit_transform_model","text":"fit bertopic model cleaned data","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_transform_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fit a bertopic model to cleaned data — bt_fit_transform_model","text":"","code":"bt_fit_transform_model(   cleaned_text,   calculated_embeddings = NULL,   reducer = NULL,   min_topic_size = 10,   nr_topics = NULL,   ngram_range = c(1, 1),   embedding_model = \"all-MiniLM-L6-v2\",   accelerator = \"mps\",   diversity = 0.1,   stopwords = TRUE,   random_state = NULL )"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_transform_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fit a bertopic model to cleaned data — bt_fit_transform_model","text":"cleaned_text cleaned text column model fit calculated_embeddings embeddings already calculated input embeddings matrix reducer dimensionality reduction model send BERTopic() min_topic_size minimum topic size nr_topics number topics find within dataset ngram_range ngram range topic representation embedding_model embedding model use used produce embeddings accelerator accelerator use - default mps, use NULL none diversity diversity topic representation (1 = diverse, 0 = diverse) stopwords whether remove stopwords topic representations random_state random state pass umap","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_fit_transform_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"fit a bertopic model to cleaned data — bt_fit_transform_model","text":"list containing fitted bertopic model embeddings used fit model","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a clustering model — bt_make_clusterer","title":"Create a clustering model — bt_make_clusterer","text":"Instantiates clustering model can fed BertopicR pipeline.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a clustering model — bt_make_clusterer","text":"","code":"bt_make_clusterer(   ...,   clustering_method = c(\"hdbscan\", \"kmeans\", \"agglomerative\", \"base\") )"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a clustering model — bt_make_clusterer","text":"... Arguments fed clustering function determined clustering_method = clustering_method string defining clustering method use","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a clustering model — bt_make_clusterer","text":"clustering model (Python object)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a clustering model — bt_make_clusterer","text":"Available clustering models 'hdbscan', 'kmeans', 'agglomerative', 'base'. options, see either hdbscan, sklearn official documentation lists arguments can fed clustering model. type \"?bt_make_clusterer_hdbscan\", \"?bt_make_clusterer_kmeans\" etc. see named arguments supplied default clustering model. Executing \"bt_make_clusterer(clustering_method = 'base')\" equivalent calling `\"bt_base_clusterer()\" returns empty model used streamlining topic modelling process.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a clustering model — bt_make_clusterer","text":"","code":"empty_clustering_model <- bt_make_clusterer(clustering_method = \"base\")  hdbscan_model <- bt_make_clusterer(clustering_method = \"hdbscan\", min_cluster_size = 10L)  kmeans_model <- bt_make_clusterer(clustering_method = \"kmeans\", n_clusters = 10L)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_agglomerative.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an Agglomerative Clustering clustering model — bt_make_clusterer_agglomerative","title":"Create an Agglomerative Clustering clustering model — bt_make_clusterer_agglomerative","text":"Create Agglomerative Clustering clustering model","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_agglomerative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an Agglomerative Clustering clustering model — bt_make_clusterer_agglomerative","text":"","code":"bt_make_clusterer_agglomerative(n_clusters = 20L)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_agglomerative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an Agglomerative Clustering clustering model — bt_make_clusterer_agglomerative","text":"n_clusters number clusters search (enter integer typing L number)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_agglomerative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an Agglomerative Clustering clustering model — bt_make_clusterer_agglomerative","text":"Agglomerative Clustering clustering model (Python object)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_agglomerative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an Agglomerative Clustering clustering model — bt_make_clusterer_agglomerative","text":"","code":"clustering_model <- bt_make_clusterer_agglomerative(15L)  agglomerative_model <- bt_make_clusterer_agglomerative(n_clusters = 10L)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_hdbscan.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an HDBSCAN clustering model — bt_make_clusterer_hdbscan","title":"Create an HDBSCAN clustering model — bt_make_clusterer_hdbscan","text":"Instantiates HDBSCAN clustering model using hdbscan Python library.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_hdbscan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an HDBSCAN clustering model — bt_make_clusterer_hdbscan","text":"","code":"bt_make_clusterer_hdbscan(   ...,   min_cluster_size = 10L,   metric = \"euclidean\",   cluster_selection_method = \"eom\",   prediction_data = FALSE )"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_hdbscan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an HDBSCAN clustering model — bt_make_clusterer_hdbscan","text":"... Additional arguments sent hdbscan.HDBSCAN() min_cluster_size Minimum number data points cluster, enter integer adding L number metric Distance metric calculate clusters cluster_selection_method method used select clusters. Default \"eom\". prediction_data Logical","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_hdbscan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an HDBSCAN clustering model — bt_make_clusterer_hdbscan","text":"instance HDBSCAN clustering model (Python object.","code":""},{"path":[]},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_hdbscan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an HDBSCAN clustering model — bt_make_clusterer_hdbscan","text":"","code":"clustering_model <- bt_make_clusterer_hdbscan(metric = \"minkowski\")"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a kmeans clustering model — bt_make_clusterer_kmeans","title":"Create a kmeans clustering model — bt_make_clusterer_kmeans","text":"Create kmeans clustering model","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a kmeans clustering model — bt_make_clusterer_kmeans","text":"","code":"bt_make_clusterer_kmeans(n_clusters = 10L)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a kmeans clustering model — bt_make_clusterer_kmeans","text":"n_clusters number clusters search (enter integer typing L number)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_kmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a kmeans clustering model — bt_make_clusterer_kmeans","text":"kMeans clustering model (Python object)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_clusterer_kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a kmeans clustering model — bt_make_clusterer_kmeans","text":"","code":"clustering_model <- bt_make_clusterer_kmeans(15L)  kmeans_model <- bt_make_clusterer_kmeans(n_clusters = 10L)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_ctfidf.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an instance of the ClassTfidfTransformer from the bertopic.vectorizers module — bt_make_ctfidf","title":"Create an instance of the ClassTfidfTransformer from the bertopic.vectorizers module — bt_make_ctfidf","text":"function creates instance ClassTfidfTransformer bertopic.vectorizers module, provided arguments. used generate representations topics selecting words frequent within topic less frequent entire corpus.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_ctfidf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an instance of the ClassTfidfTransformer from the bertopic.vectorizers module — bt_make_ctfidf","text":"","code":"bt_make_ctfidf(reduce_frequent_words = TRUE, bm25_weighting = FALSE)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_ctfidf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an instance of the ClassTfidfTransformer from the bertopic.vectorizers module — bt_make_ctfidf","text":"reduce_frequent_words frequent words reduced? Default TRUE. bm25_weighting BM25 weighting used? Default FALSE.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_ctfidf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an instance of the ClassTfidfTransformer from the bertopic.vectorizers module — bt_make_ctfidf","text":"ctfidf model (Python object).","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_df.html","id":null,"dir":"Reference","previous_headings":"","what":"make a df combining bertopic output with columns in original data export — bt_make_df","title":"make a df combining bertopic output with columns in original data export — bt_make_df","text":"make df combining bertopic output columns original data export","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make a df combining bertopic output with columns in original data export — bt_make_df","text":"","code":"bt_make_df( df, model, embeddings, text_var = message, date_var = created_time)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make a df combining bertopic output with columns in original data export — bt_make_df","text":"df original Sprinklr export topic modelling performed merge bertopic output model bertopic model embeddings embeddings used generate model text_var original, uncleaned text column, text used fit model date_var date column df corresponding text used fit model","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make a df combining bertopic output with columns in original data export — bt_make_df","text":"df bertopic output merged input columns sprinkr export","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_embedder.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an embedding model — bt_make_embedder","title":"Create an embedding model — bt_make_embedder","text":"Initially function built upon sentence_transformers Python library, may expanded accept frameworks. feed documents list. can use hardware accelerators e.g. GPUs, speed computation.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_embedder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an embedding model — bt_make_embedder","text":"","code":"bt_make_embedder(model_name)"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_embedder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an embedding model — bt_make_embedder","text":"model_name Name embedding model string (case sensitive)","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_embedder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an embedding model — bt_make_embedder","text":"Python object","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_embedder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an embedding model — bt_make_embedder","text":"","code":"embedder <- bt_make_embedder(\"all-mpnet-base-v2\")  embedder <- bt_make_embedder(\"aLL-minilm-l6-v2\")"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_reducer.html","id":null,"dir":"Reference","previous_headings":"","what":"Create dimensionality reduction model — bt_make_reducer","title":"Create dimensionality reduction model — bt_make_reducer","text":"function wraps UMAP functionality Python's umap-learn package use R via reticulate. allows perform dimension reduction high-dimensional data, intended use BertopicR pipeline/","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_reducer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create dimensionality reduction model — bt_make_reducer","text":"","code":"bt_make_reducer(   ...,   n_neighbors = 15L,   n_components = 5L,   min_dist = 0,   metric = \"euclidean\",   random_state = 42L,   verbose = TRUE )"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_reducer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create dimensionality reduction model — bt_make_reducer","text":"... Sent umap$UMAP adding additional arugments n_neighbors size local neighbourhood (terms number neighboring data points) used manifold approximation (default: 15). n_components number dimensions reduce (default: 5). min_dist minimum distance points low-dimensional representation (default: 0.0). metric metric use distance computation (default: \"euclidean\"). random_state seed used random number generator (default: 42). verbose Logical flag indicating whether report progress dimension reduction (default: TRUE).","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_reducer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create dimensionality reduction model — bt_make_reducer","text":"matrix data frame dimension-reduced data. number rows embeddings, number columns n_components.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_reducer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create dimensionality reduction model — bt_make_reducer","text":"concerned processing time, likely want reduce dimensions dataset . case, call reducer <- bt_base_reducer()","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_vectoriser.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a text vectoriser — bt_make_vectoriser","title":"Create a text vectoriser — bt_make_vectoriser","text":"function uses Python's sklearn feature extraction count vectorisation. creates CountVectorizer object specified parameters. CountVectorizer way convert text data vectors model input. Used inside BertopicR topc modelling pipeline.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_vectoriser.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a text vectoriser — bt_make_vectoriser","text":"","code":"bt_make_vectoriser(   ...,   ngram_range = c(1, 2),   stop_words = \"english\",   min_frequency = 10L,   max_features = NULL )"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_vectoriser.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a text vectoriser — bt_make_vectoriser","text":"... Additional parameters passed sklearn's CountVectorizer ngram_range vector length 2 (default c(1, 2)) indicating lower upper boundary range n-values different word n-grams char n-grams extracted features. values n min_n <= n <= max_n used. example ngram_range c(1, 1) means unigrams, c(1, 2) means unigrams bigrams, c(2, 2) means bigrams. stop_words String (default 'english'). string, passed _check_stop_list appropriate stop list returned. 'english' currently default. min_frequency Integer (default 10L). building vocabulary ignore terms corpus frequency strictly lower given threshold. max_features Integer NULL (default NULL). NULL, build vocabulary considers top max_features ordered term frequency across corpus.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_make_vectoriser.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a text vectoriser — bt_make_vectoriser","text":"sklearn CountVectorizer object configured provided parameters","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_diff_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","title":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","text":"Function find terms greatest difference topics","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_diff_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","text":"","code":"bt_viz_diff_terms(   merged_df,   text_var = text_clean,   topic_var = topic,   top_n = 15,   min_freq = 25,   include_outliers = FALSE,   type = c(\"lollipops\", \"bars\"),   plots = NULL )"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_diff_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","text":"merged_df output makedf function.Can df includes topic column text_var text diff_terms extracted topic_var column containing topic variable top_n number terms extract min_freq minimum number times term appear considered include_outliers include outlier (-1) bertopic category? type lollipop bar chart plots specific plots output. input c(x, y) want 1 chart list(c(x, y), c(u, v)) x, y, u v topic numbers.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_diff_terms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to find terms with the greatest difference between topics — bt_viz_diff_terms","text":"ggplot object top different terms pair topics","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_top_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","title":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","text":"create top terms charts topic modelling completed using bertopic","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_top_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","text":"","code":"bt_viz_top_terms(   merged_df,   text_var = text_clean,   topic_var = topic,   top_n = 15,   n_row = 2,   min_freq = 25,   include_outliers = FALSE,   type = c(\"lollipops\", \"bars\") )"},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_top_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","text":"merged_df df output makedf function.Can df includes topic column text_var text top terms extracted topic_var column containing topic variable top_n number terms extract n_row number rows plots take min_freq minimum number times term appear considered include_outliers include -1 (outlier) bertopic category type lollipop bar chart?","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/bt_viz_top_terms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"create top terms charts for topic modelling completed using bertopic — bt_viz_top_terms","text":"list all_terms max_only top term bar charts","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/check_python_dependencies.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that dependencies are loaded — check_python_dependencies","title":"Check that dependencies are loaded — check_python_dependencies","text":"Check dependencies loaded","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/check_python_dependencies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that dependencies are loaded — check_python_dependencies","text":"","code":"check_python_dependencies()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/check_python_dependencies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that dependencies are loaded — check_python_dependencies","text":"message confirming whether dependencies loaded","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/install_python_dependencies.html","id":null,"dir":"Reference","previous_headings":"","what":"Install Python Dependencies — install_python_dependencies","title":"Install Python Dependencies — install_python_dependencies","text":"Install Python Dependencies","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/install_python_dependencies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install Python Dependencies — install_python_dependencies","text":"","code":"install_python_dependencies()"},{"path":"https://jpcompartir.github.io/BertopicR/reference/install_python_dependencies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Install Python Dependencies — install_python_dependencies","text":"Nothing","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://jpcompartir.github.io/BertopicR/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://jpcompartir.github.io/BertopicR/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""}]
