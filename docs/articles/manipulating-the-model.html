<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="BertopicR">
<title>Manipulating the Model • BertopicR</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Manipulating the Model">
<meta property="og:description" content="BertopicR">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">BertopicR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../articles/index.html">Articles</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/AoifeRyan-sc/BertopicR" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">



<script src="manipulating-the-model_files/htmlwidgets-1.6.2/htmlwidgets.js"></script><link href="manipulating-the-model_files/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="manipulating-the-model_files/datatables-binding-0.29/datatables.js"></script><link href="manipulating-the-model_files/dt-core-1.13.4/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="manipulating-the-model_files/dt-core-1.13.4/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="manipulating-the-model_files/dt-core-1.13.4/js/jquery.dataTables.min.js"></script><link href="manipulating-the-model_files/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="manipulating-the-model_files/crosstalk-1.2.0/js/crosstalk.min.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Manipulating the Model</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/AoifeRyan-sc/BertopicR/tree/branching-before-segmentation-error/vignettes/manipulating-the-model.Rmd" class="external-link"><code>vignettes/manipulating-the-model.Rmd</code></a></small>
      <div class="d-none name"><code>manipulating-the-model.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://jpcompartir.github.io/BertopicR/" class="external-link">BertopicR</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org" class="external-link">tidyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: package 'ggplot2' was built under R version 4.3.1</span></span></code></pre></div>
<div class="section level2">
<h2 id="changing-the-model-representation">Changing the Model Representation<a class="anchor" aria-label="anchor" href="#changing-the-model-representation"></a>
</h2>
<pre><code><span><span class="co">#&gt; UMAP(low_memory=False, min_dist=0, n_components=5, n_neighbors=10, random_state=42, verbose=True)</span></span>
<span><span class="co">#&gt; Fri Oct 20 08:34:33 2023 Construct fuzzy simplicial set</span></span>
<span><span class="co">#&gt; Fri Oct 20 08:34:34 2023 Finding Nearest Neighbors</span></span>
<span><span class="co">#&gt; Fri Oct 20 08:34:35 2023 Finished Nearest Neighbor Search</span></span>
<span><span class="co">#&gt; Fri Oct 20 08:34:37 2023 Construct embedding</span></span>
<span><span class="co">#&gt; Fri Oct 20 08:34:38 2023 Finished embedding</span></span></code></pre>
<p>Once you are happy with the topics/clusters that have been formed,
there are a few methods we can use to improve the topic representations
and get a better understanding of what each topic is about.</p>
<p>The representation methods currently available are:</p>
<ol style="list-style-type: decimal">
<li><p><strong>KeyBERT</strong> is a keyword extraction technique that
uses BERT embeddings to represent our topics with appropriate keywords
and phrases.</p></li>
<li><p><strong>MaximalMarginalRelevance</strong> is a concept used to
select the most relevant keywords or phrases while promoting diversity
in keywords. It balances relevance to the topic with distinctiveness
from previously chosen keywords or phrases using a trade-off parameter
called lambda.</p></li>
<li><p><strong>OpenAI</strong> allows us to use their available models
to generate topic summaries. An OpenAI API key is required to access
their api and models (to set this you should use
Sys.setenv(“OPENAI_API_KEY” = “sk-”)).</p></li>
<li><p><strong>HuggingFace</strong> allows us to use their available
models to generate topic summaries. Unlike with OpenAI, you will not
need an API key and this is completely free. However, the models are not
as sophisticated as some of OpenAI’s.</p></li>
</ol>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">representation_keybert</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_representation_keybert.html">bt_representation_keybert</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                                    documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                                    document_embeddings <span class="op">=</span> <span class="va">embeddings</span>,</span>
<span>                                                    embedding_model <span class="op">=</span> <span class="va">embedder</span>,</span>
<span>                                                    top_n_words <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                                                    nr_repr_docs <span class="op">=</span> <span class="fl">50</span>,</span>
<span>                                                    nr_samples <span class="op">=</span> <span class="fl">500</span>,</span>
<span>                                                    nr_candidate_words <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="va">representation_mmr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_representation_mmr.html">bt_representation_mmr</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                            embedding_model <span class="op">=</span> <span class="va">embedder</span>,</span>
<span>                                            diversity <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="va">representation_openai</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_representation_openai.html">bt_representation_openai</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                                  documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                                  openai_model <span class="op">=</span> <span class="st">"gpt-3.5-turbo"</span>,</span>
<span>                                                  nr_repr_docs <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                                                  chat <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                                                  api_key <span class="op">=</span> <span class="st">"sk-"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">representation_hf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_representation_hf.html">bt_representation_hf</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                          documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                          task <span class="op">=</span> <span class="st">"text2text-generation"</span>,</span>
<span>                                          hf_model <span class="op">=</span> <span class="st">"google/flan-t5-base"</span>,</span>
<span>                                          default_prompt <span class="op">=</span> <span class="st">"keywords"</span><span class="op">)</span></span></code></pre></div>
<p>Now that we have trialled a few representation methods, we can look
at how they compare to default representations and we should be able to
get a good idea of what each topic is about. You will notice that the
gpt-3.5 model gives the most coherent topic representation and it would
be easy to just take that as gospel and chose a topic title based on
that. It is important to remember, like with the other representation
methods, only the number you input for nr_repr_docs in
bt_representation_openai has been sent to the model and for a large
topic, these documents may not represent the topic as a whole.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">topic_representations</span> <span class="op">&lt;-</span> <span class="va">topic_model</span><span class="op">$</span><span class="fu">get_topic_info</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>keybert <span class="op">=</span> <span class="va">representation_keybert</span>,</span>
<span>         mmr <span class="op">=</span> <span class="va">representation_mmr</span>,</span>
<span>         <span class="co"># openai = representation_openai,</span></span>
<span>         flanT5 <span class="op">=</span> <span class="va">representation_hf</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Representative_Docs</span><span class="op">)</span></span>
<span></span>
<span><span class="va">topic_representations</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">Topic</span>, <span class="op">-</span><span class="va">Count</span>, <span class="op">-</span><span class="va">Name</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>keybert <span class="op">=</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_replace.html" class="external-link">str_replace_all</a></span><span class="op">(</span><span class="va">keybert</span>, <span class="st">"_"</span>,<span class="st">", "</span><span class="op">)</span>,</span>
<span>         mmr <span class="op">=</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_replace.html" class="external-link">str_replace_all</a></span><span class="op">(</span><span class="va">mmr</span>, <span class="st">"_"</span>,<span class="st">", "</span><span class="op">)</span>,</span>
<span>         Representation <span class="op">=</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_replace.html" class="external-link">str_replace_all</a></span><span class="op">(</span><span class="va">Representation</span>, <span class="st">"_"</span>,<span class="st">", "</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">DT</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/DT/man/datatable.html" class="external-link">datatable</a></span><span class="op">(</span>options <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>scrollX <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: There was 1 warning in `mutate()`.</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> In argument: `Representation = stringr::str_replace_all(Representation, "_",</span></span>
<span><span class="co">#&gt;   ", ")`.</span></span>
<span><span class="co">#&gt; Caused by warning in `stri_replace_all_regex()`:</span></span>
<span><span class="co">#&gt; <span style="color: #BBBB00;">!</span> argument is not an atomic vector; coercing</span></span></code></pre></div>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-bb9a4c31991100561ddd" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-bb9a4c31991100561ddd">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59"],["c(\"deep\", \"night\", \"wall\", \"dust\", \"corner\", \"moved\", \"sweet\", \"salt\", \"end\", \"air\")","c(\"slide\", \"straight\", \"open\", \"wooden\", \"near\", \"line\", \"knife\", \"crack\", \"quick\", \"port\")","c(\"saw\", \"dog\", \"child\", \"quick\", \"gave\", \"tell\", \"street\", \"house\", \"right\", \"black\")","c(\"hung\", \"work\", \"carved\", \"quite\", \"knife\", \"torn\", \"seen\", \"little\", \"hold\", \"needs\")","c(\"men\", \"act\", \"neat\", \"win\", \"tried\", \"tales\", \"little\", \"fast\", \"better\", \"serve\")","c(\"house\", \"dried\", \"heavy\", \"gives\", \"torn\", \"carved\", \"stood\", \"saw\", \"moved\", \"hold\")","c(\"add\", \"help\", \"base\", \"seven\", \"hands\", \"finish\", \"drop\", \"bad\", \"great\", \"fast\")","c(\"child\", \"hands\", \"far\", \"swan\", \"sent\", \"poor\", \"boat\", \"children\", \"young\", \"little\")","c(\"straw\", \"screen\", \"near\", \"lawn\", \"gives\", \"drop\", \"beat\", \"dust\", \"corner\", \"coat\")","c(\"contents\", \"lawn\", \"went\", \"waste\", \"tree\", \"pipe\", \"burned\", \"shone\", \"crack\", \"brown\")","c(\"taste\", \"cut\", \"tree\", \"served\", \"sent\", \"knife\", \"children\", \"ice\", \"lack\", \"fine\")","c(\"air\", \"tree\", \"pink\", \"near\", \"drifts\", \"brought\", \"street\", \"edge\", \"way\", \"hung\")","c(\"screen\", \"sat\", \"laugh\", \"went\", \"feet\", \"children\", \"store\", \"start\", \"sound\", \"home\")","c(\"sound\", \"leaves\", \"grass\", \"turn\", \"pipe\", \"wet\", \"dirt\", \"brown\", \"dry\", \"fence\")","c(\"home\", \"week\", \"quite\", \"long\", \"start\", \"friends\", \"day\", \"dog\", \"ran\", \"words\")","c(\"spring\", \"tender\", \"need\", \"food\", \"drink\", \"needed\", \"came\", \"horse\", \"road\", \"grass\")","c(\"drifts\", \"seen\", \"pink\", \"north\", \"stood\", \"soft\", \"salt\", \"low\", \"edge\", \"dry\")","c(\"dried\", \"stain\", \"spot\", \"wet\", \"lead\", \"paper\", \"read\", \"dry\", \"black\", \"cut\")","c(\"rare\", \"served\", \"far\", \"bowl\", \"bell\", \"serve\", \"better\", \"pot\", \"round\", \"good\")","c(\"don\", \"cause\", \"turn\", \"tales\", \"need\", \"laugh\", \"write\", \"bad\", \"friends\", \"form\")","c(\"week\", \"tried\", \"quite\", \"needed\", \"great\", \"come\", \"bank\", \"worn\", \"man\", \"dull\")","c(\"desk\", \"sat\", \"sad\", \"office\", \"paint\", \"blue\", \"light\", \"hung\", \"floor\", \"wide\")","c(\"win\", \"line\", \"lead\", \"heavy\", \"crack\", \"cause\", \"strong\", \"stood\", \"sound\", \"help\")","c(\"fly\", \"bring\", \"gives\", \"turn\", \"waste\", \"loud\", \"north\", \"boat\", \"little\", \"low\")","c(\"right\", \"tried\", \"drop\", \"cause\", \"bad\", \"lost\", \"just\", \"don\", \"hard\", \"new\")","c(\"write\", \"seven\", \"open\", \"finish\", \"fast\", \"cloth\", \"early\", \"paper\", \"make\", \"good\")","c(\"tall\", \"horse\", \"cup\", \"contents\", \"soft\", \"brown\", \"man\", \"\", \"\", \"\")","c(\"low\", \"beat\", \"lead\", \"end\", \"kept\", \"mark\", \"just\", \"hung\", \"took\", \"man\")","c(\"tight\", \"straw\", \"covered\", \"tell\", \"door\", \"kept\", \"\", \"\", \"\", \"\")","c(\"long\", \"lines\", \"seven\", \"heavy\", \"carved\", \"base\", \"read\", \"great\", \"form\", \"black\")","c(\"pack\", \"office\", \"neat\", \"slide\", \"add\", \"takes\", \"leaves\", \"store\", \"paper\", \"wall\")","c(\"feet\", \"brought\", \"moved\", \"day\", \"big\", \"wide\", \"road\", \"night\", \"\", \"\")","c(\"pink\", \"soft\", \"small\", \"used\", \"blue\", \"round\", \"\", \"\", \"\", \"\")","c(\"pure\", \"neat\", \"clean\", \"worn\", \"took\", \"girl\", \"wide\", \"tea\", \"man\", \"\")","c(\"pipe\", \"spring\", \"tell\", \"ran\", \"mark\", \"cut\", \"clear\", \"small\", \"\", \"\")","c(\"times\", \"lines\", \"drifts\", \"dirt\", \"road\", \"street\", \"dust\", \"deep\", \"men\", \"sharp\")","c(\"tender\", \"odor\", \"dirt\", \"cloth\", \"water\", \"brass\", \"sharp\", \"fine\", \"\", \"\")","c(\"ship\", \"lost\", \"port\", \"torn\", \"big\", \"sharp\", \"hard\", \"\", \"\", \"\")","c(\"come\", \"bell\", \"salt\", \"pack\", \"time\", \"don\", \"new\", \"\", \"\", \"\")","c(\"times\", \"swan\", \"sad\", \"laugh\", \"great\", \"friends\", \"tall\", \"takes\", \"like\", \"wide\")","c(\"line\", \"serve\", \"clean\", \"needs\", \"straight\", \"left\", \"\", \"\", \"\", \"\")","c(\"win\", \"poor\", \"china\", \"bank\", \"pack\", \"early\", \"bright\", \"way\", \"good\", \"\")","c(\"cold\", \"north\", \"start\", \"fly\", \"bring\", \"smell\", \"deep\", \"work\", \"air\", \"\")","c(\"words\", \"sweet\", \"better\", \"lost\", \"work\", \"make\", \"clear\", \"strong\", \"\", \"\")","c(\"words\", \"times\", \"office\", \"takes\", \"strong\", \"\", \"\", \"\", \"\", \"\")","c(\"port\", \"taste\", \"hold\", \"water\", \"strong\", \"\", \"\", \"\", \"\", \"\")","c(\"loud\", \"china\", \"street\", \"bank\", \"black\", \"big\", \"set\", \"floor\", \"red\", \"\")","c(\"fence\", \"square\", \"spot\", \"straw\", \"long\", \"mark\", \"door\", \"sharp\", \"red\", \"\")","c(\"sun\", \"shone\", \"bowl\", \"came\", \"hot\", \"white\", \"light\", \"red\", \"wide\", \"road\")","c(\"smell\", \"stain\", \"odor\", \"hands\", \"burned\", \"cloth\", \"bring\", \"better\", \"takes\", \"green\")","c(\"sat\", \"fast\", \"rose\", \"like\", \"\", \"\", \"\", \"\", \"\", \"\")","c(\"brass\", \"shone\", \"clean\", \"bright\", \"like\", \"new\", \"wall\", \"high\", \"\", \"\")","c(\"ice\", \"cold\", \"pure\", \"bowl\", \"came\", \"early\", \"make\", \"water\", \"green\", \"\")","c(\"gave\", \"contents\", \"form\", \"pot\", \"girl\", \"clear\", \"young\", \"\", \"\", \"\")","c(\"paint\", \"lines\", \"covered\", \"edge\", \"corner\", \"ran\", \"coat\", \"black\", \"left\", \"fine\")","c(\"door\", \"food\", \"needed\", \"bad\", \"red\", \"old\", \"\", \"\", \"\", \"\")","c(\"tea\", \"served\", \"pot\", \"brown\", \"\", \"\", \"\", \"\", \"\", \"\")","c(\"box\", \"square\", \"seen\", \"wooden\", \"paper\", \"bright\", \"red\", \"high\", \"\", \"\")","c(\"food\", \"drink\", \"cup\", \"covered\", \"sweet\", \"hot\", \"makes\", \"hard\", \"fine\", \"old\")"],["outliers","knife, round, sharp, wooden, quick, crack, open, end, slide, cut","fence, house, quick, saw, street, light, gave, black, takes, high","carved, hung, brass, hold, knife, quite, bright, coat, fine, work","little, neat, fast, work, night, tales, right, win, early, serve","wall, dried, water, dry, round, saw, carved, floor, stood, house","old, act, finish, seven, hands, help, day, new, drop, takes","poor, swan, coat, children, little, rose, child, boat, small, came","straw, corner, dust, beat, lawn, near, high, coat, lack, gives","box, lawn, waste, leaves, shone, house, paper, tree, contents, light","ice, knife, tree, kept, taste, cut, used, children, makes, lack","round, hung, tree, drifts, air, pink, sun, street, blue, near","feet, home, laugh, children, high, straight, sound, store, screen, left","dirt, grass, pipe, wet, fence, dry, leaves, turn, brown, clear","ran, kept, words, dull, quite, took, day, long, friends, new","grass, drink, horse, road, food, tender, way, man, spring, need","salt, drifts, dry, stood, water, soft, edge, old, came, rose","sharp, dry, paper, wet, dried, stain, cut, black, spot, lead","bowl, serve, pot, bell, round, good, served, better, rare, new","dull, cause, laugh, make, bad, small, don, like, write, form","worn, dull, week, come, good, quite, old, bank, tried, man","desk, floor, dull, wall, paint, hung, light, strong, sad, blue","stood, win, help, strong, line, set, sound, crack, time, heavy","light, road, lack, night, little, gives, boat, time, waste, bring","tried, drop, lost, right, cause, just, bad, hard, new, old","write, paper, finish, make, fast, cloth, good, open, seven, early","horse, brown, cup, tall, contents, man, soft","end, hung, kept, lead, took, man, good, mark, low, best","door, straw, kept, tell, tight, covered","carved, base, great, black, heavy, lines, form, long, large, seven","leaves, neat, wall, pack, slide, store, takes, paper, office, add","feet, wide, moved, road, night, brought, day, big","round, pink, small, blue, used, soft","tea, worn, wide, pure, clean, man, took, neat, girl","pipe, cut, mark, tell, clear, small, ran, spring","dirt, road, drifts, sharp, lines, dust, street, deep, men, times","brass, sharp, water, cloth, tender, odor, fine, dirt","sharp, lost, torn, port, hard, big, ship","don, bell, time, come, pack, salt, new","sad, swan, laugh, friends, old, like, wide, takes, tall, times","clean, left, straight, serve, line, needs","pack, bank, bright, way, win, poor, china, early, good","fly, air, north, smell, work, cold, deep, bring, start","work, clear, make, strong, lost, better, sweet, words","strong, takes, office, times, words","water, strong, hold, taste, port","loud, black, bank, floor, street, red, china, set, big","straw, sharp, long, fence, mark, spot, door, square, red","shone, road, came, wide, bowl, white, red, light, hot, sun","stain, hands, burned, bring, green, cloth, takes, smell, odor, better","rose, like, fast, sat","shone, new, wall, bright, high, brass, like, clean","green, bowl, cold, water, ice, make, early, came, pure","clear, gave, contents, form, pot, young, girl","covered, lines, fine, paint, coat, ran, black, corner, edge, left","food, door, red, old, bad, needed","brown, pot, tea, served","wooden, bright, paper, seen, red, box, square, high","covered, food, cup, fine, drink, old, sweet, hot, makes, hard"],["outliers","knife, port, open, quick, crack, wooden, line, straight, near, slide","dog, black, street, house, child, right, quick, tell, gave, saw","knife, carved, little, needs, work, quite, torn, seen, hold, hung","serve, win, fast, tales, tried, act, neat, better, little, men","house, dried, carved, saw, torn, stood, heavy, hold, gives, moved","drop, hands, base, fast, seven, bad, finish, help, great, add","children, swan, boat, hands, far, poor, sent, little, young, child","dust, lawn, screen, corner, drop, coat, near, beat, gives, straw","lawn, pipe, burned, brown, tree, waste, crack, shone, went, contents","knife, tree, ice, sent, served, cut, children, fine, lack, taste","street, drifts, tree, hung, edge, pink, brought, way, near, air","screen, laugh, children, home, feet, sound, start, store, went, sat","dirt, grass, wet, dry, pipe, fence, leaves, brown, turn, sound","week, dog, words, long, friends, ran, day, start, quite, home","grass, horse, needed, road, need, food, tender, came, drink, spring","drifts, pink, north, dry, salt, stood, seen, soft, low, edge","stain, paper, lead, read, black, spot, cut, wet, dry, dried","bell, bowl, serve, pot, round, served, far, better, good, rare","tales, friends, turn, bad, laugh, form, write, cause, need, don","worn, dull, tried, needed, bank, quite, come, man, great, week","desk, blue, sad, paint, light, hung, wide, floor, sat, office","crack, sound, strong, lead, line, stood, heavy, help, cause, win","fly, boat, low, north, waste, loud, turn, little, bring, gives","drop, lost, new, tried, bad, hard, don, just, cause, right","paper, cloth, early, fast, seven, open, finish, good, make, write","horse, cup, brown, contents, man, soft, , , , tall","mark, hung, end, man, lead, beat, took, kept, just, low","door, straw, covered, kept, , , , , tell, tight","lines, carved, base, black, form, read, heavy, seven, great, long","slide, paper, office, wall, leaves, neat, add, takes, store, pack","feet, road, night, day, moved, brought, wide, , , big","pink, round, soft, small, used, , , , , blue","tea, worn, man, girl, clean, took, wide, neat, , pure","pipe, spring, mark, cut, ran, small, clear, tell, , ","lines, road, street, drifts, deep, dirt, sharp, dust, men, times","odor, dirt, brass, cloth, water, sharp, , , fine, tender","port, sharp, torn, hard, lost, big, , , , ship","bell, salt, new, pack, time, don, , , , come","tall, wide, swan, laugh, friends, sad, like, great, takes, times","line, serve, clean, left, straight, , , , , needs","win, china, bright, early, bank, pack, poor, , way, good","air, fly, north, smell, work, deep, start, , bring, cold","words, lost, work, clear, strong, better, sweet, , , make","office, strong, times, takes, , , , , , words","port, taste, water, strong, hold, , , , , ","loud, bank, red, set, floor, china, black, street, , big","fence, red, straw, square, spot, door, mark, , sharp, long","bowl, road, came, wide, red, shone, hot, white, light, sun","odor, green, stain, cloth, burned, better, hands, takes, bring, smell","rose, like, fast, , , , , , , sat","brass, shone, bright, high, clean, like, new, wall, , ","water, bowl, green, make, early, pure, came, , cold, ice","pot, girl, young, contents, clear, form, , , , gave","paint, left, corner, lines, covered, edge, ran, black, fine, coat","door, food, red, bad, old, needed, , , , ","tea, brown, served, , , , , , , pot","box, square, wooden, paper, red, seen, bright, high, , ","cup, hot, sweet, hard, covered, old, drink, makes, fine, food"],[["outliers"],["a knife that slides into a port"],["a black dog gave a quick tell to a child in the street"],["carved wooden work"],["a man who tried to act neat and win a match"],["carved house with a carved wooden frame"],["a hat trick"],["swans sent by a boat"],["a sandbox gives a sanding blow to the lawn near "],["ash and ash from a fire sparked a fire on a lawn"],["a knife for serving ice"],["pink tree hung on the edge of a street"],["a child sat on a computer screen and listened to a funny sound"],["a pipe turns a dark brown, wet, dirt into a pipe"],["a dog ran into my home on a long day and started to talk to me about"],["horse came in spring for food and drink"],["drifting drifts in the north"],["black and white striped paper with a black stain on the front"],["bell peppers"],["a story that doesn't make you laugh"],["i want to come back to the bank and try again."],["a sad desk sat on the floor in an office"],["a strong strong sound helped lead to a win"],["flies north and gives a loud rumbling sound as it flies north"],["don't drop the ball"],["a letter opener"],["a man with a cup of coffee with a horse"],["john mccarthy beat a man to the end of the game"],["straw covered door"],["black and white carved sphinx with long lines and a base"],["a pack of leaves and a stack of paper in an office"],["a giraffe brought feet on a wide road in the day"],["pink round teddy bear"],["a man takes a wide, clean, and dirty look at a woman who is"],["pipe running through a stream"],["road with sharp lines and drifts of dirt and dust"],["a tad more than a tad more than a "],["a ship torn off the coast of a port"],["pack a new salt in a pack"],["swans take time to laugh and cry like they are in a movie"],["a straight line of food that needs to be cleaned"],["china wins a big way to win a big way to win a big way to"],["flying in the north brings the coldest air in the world"],["i lost my job"],["i took my office to the office and it was a very strong office"],["port"],["a set of red carpeted floors in a bank in china"],["red fence with a red door"],["red bowl of ice cream came out of the sun"],["bringing green to your hands with a cloth"],["i like roses sat fast ."],["brightly shining brass wall"],["bowl of pure ice"],["young girl giving a pot of contents to a young girl"],["black and white striped coat of paint on the edge of a corner"],["red door for old food"],["brown tea served in a pot"],["red and white squares on a wooden box"],["coffee cup makes a fine cup of hot coffee"]]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Representation<\/th>\n      <th>keybert<\/th>\n      <th>mmr<\/th>\n      <th>flanT5<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"scrollX":true,"columnDefs":[{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div class="section level2">
<h2 id="modifying-topics">Modifying Topics<a class="anchor" aria-label="anchor" href="#modifying-topics"></a>
</h2>
<p>Two of the biggest inconveniences that using hdbscan clustering
introduces is the generation of large numbers of clusters (topics) and
the presence of what can be huge numbers of outliers. In order for our
topic analysis to be practical and digestible, we will likely want to
reduce the number of topics and, depending on our use case, we may want
to reduce the number of outliers.</p>
<div class="section level3">
<h3 id="merging-topics">Merging Topics<a class="anchor" aria-label="anchor" href="#merging-topics"></a>
</h3>
<p>Particularly when using hdbscan we can end up with a large number of
topics and it can be useful to merge some of these topics which we think
are suitably similar. We can get a certain idea about this from the
topic descriptions that we have already generated, but it can also be
useful to look at the data more closely before merging.</p>
<div class="section level4">
<h4 id="hierarchical-clustering">Hierarchical Clustering<a class="anchor" aria-label="anchor" href="#hierarchical-clustering"></a>
</h4>
<p>Hdbscan clustering forms clusters through a hierarchical processes
which you can visualise with a dendrogram. This can be useful when
merging topics as you can see how clusters split to become the topics
that emerged from our topic modelling process. The x-axis here is a
measure of the distance between topic embeddings, so when clusters split
at a higher x-value there is a larger distance between their embeddings.
We can see that for this particular dataset, the clusters split into
their final topics quite early on in the hierarchy and so it might not
be appropriate to merge topics based on how they have emerged in the
hierarchy.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hierarchical_topics</span> <span class="op">&lt;-</span> <span class="va">topic_model</span><span class="op">$</span><span class="fu">hierarchical_topics</span><span class="op">(</span><span class="va">sentences</span><span class="op">)</span></span>
<span><span class="va">topic_model</span><span class="op">$</span><span class="fu">visualize_hierarchy</span><span class="op">(</span>hierarchical_topics <span class="op">=</span> <span class="va">hierarchical_topics</span><span class="op">)</span><span class="op">$</span><span class="fu">show</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code>#&gt; 
  0%|          | 0/57 [00:00&lt;?, ?it/s]
 54%|#####4    | 31/57 [00:00&lt;00:00, 309.17it/s]
100%|##########| 57/57 [00:00&lt;00:00, 313.34it/s]</code></pre>
<div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script charset="utf-8" src="https://cdn.plot.ly/plotly-2.24.1.min.js"></script><div id="243580f8-c457-49f0-b075-29babd2accdd" class="plotly-graph-div" style="height:1070px; width:1000px;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("243580f8-c457-49f0-b075-29babd2accdd")) {                    Plotly.newPlot(                        "243580f8-c457-49f0-b075-29babd2accdd",                        [{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["loud_china_street_bank_black","","","win_poor_china_bank_pack"],"x":[0.0,0.7023981972464493,0.7023981972464493,0.0],"xaxis":"x","y":[-5.0,-5.0,-15.0,-15.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["pack_office_neat_slide_add","","","come_bell_salt_pack_time"],"x":[0.0,0.8302524002939504,0.8302524002939504,0.0],"xaxis":"x","y":[-25.0,-25.0,-35.0,-35.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["china_bank_win_poor_loud","","","pack_come_bell_office_neat"],"x":[0.7023981972464493,1.0755840455610057,1.0755840455610057,0.8302524002939504],"xaxis":"x","y":[-10.0,-10.0,-30.0,-30.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["week_tried_quite_needed_great","","","home_week_quite_long_start"],"x":[0.0,0.7443195760036879,0.7443195760036879,0.0],"xaxis":"x","y":[-45.0,-45.0,-55.0,-55.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(133,20,75)"},"mode":"lines","text":["don_cause_turn_tales_need","","","right_tried_drop_cause_bad"],"x":[0.0,0.7347509556316418,0.7347509556316418,0.0],"xaxis":"x","y":[-65.0,-65.0,-75.0,-75.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(133,20,75)"},"mode":"lines","text":["men_act_neat_win_tried","","","saw_dog_child_quick_gave"],"x":[0.0,0.8828279977919145,0.8828279977919145,0.0],"xaxis":"x","y":[-85.0,-85.0,-95.0,-95.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(133,20,75)"},"mode":"lines","text":["cause_bad_don_right_need","","","men_act_tell_saw_right"],"x":[0.7347509556316418,0.9781284104581118,0.9781284104581118,0.8828279977919145],"xaxis":"x","y":[-70.0,-70.0,-90.0,-90.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["quite_week_home_tried_long","","","right_tales_cause_tried_men"],"x":[0.7443195760036879,1.070598179334618,1.070598179334618,0.9781284104581118],"xaxis":"x","y":[-50.0,-50.0,-80.0,-80.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,220,0)"},"mode":"lines","text":["add_help_base_seven_hands","","","long_lines_seven_heavy_carved"],"x":[0.0,0.72054931339644,0.72054931339644,0.0],"xaxis":"x","y":[-115.0,-115.0,-125.0,-125.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,220,0)"},"mode":"lines","text":["write_seven_open_finish_fast","","","seven_base_add_help_great"],"x":[0.0,0.8416384866044375,0.8416384866044375,0.72054931339644],"xaxis":"x","y":[-105.0,-105.0,-120.0,-120.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["tried_right_week_tales_cause","","","seven_base_finish_add_write"],"x":[1.070598179334618,1.1374289569926395,1.1374289569926395,0.8416384866044375],"xaxis":"x","y":[-65.0,-65.0,-112.5,-112.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["pack_china_come_bank_neat","","","seven_tried_write_right_act"],"x":[1.0755840455610057,1.1775474869666154,1.1775474869666154,1.1374289569926395],"xaxis":"x","y":[-20.0,-20.0,-88.75,-88.75],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["pure_neat_clean_worn_took","","","brass_shone_clean_bright_like"],"x":[0.0,0.8560031770216168,0.8560031770216168,0.0],"xaxis":"x","y":[-135.0,-135.0,-145.0,-145.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["sun_shone_bowl_came_hot","","","ice_cold_pure_bowl_came"],"x":[0.0,0.7771584036934067,0.7771584036934067,0.0],"xaxis":"x","y":[-155.0,-155.0,-165.0,-165.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["clean_brass_shone_pure_neat","","","sun_bowl_ice_cold_came"],"x":[0.8560031770216168,0.9859118874944177,0.9859118874944177,0.7771584036934067],"xaxis":"x","y":[-140.0,-140.0,-160.0,-160.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["child_hands_far_swan_sent","","","times_swan_sad_laugh_great"],"x":[0.0,0.814449685129116,0.814449685129116,0.0],"xaxis":"x","y":[-175.0,-175.0,-185.0,-185.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["desk_sat_sad_office_paint","","","sat_fast_rose_like_"],"x":[0.0,0.8134907604160901,0.8134907604160901,0.0],"xaxis":"x","y":[-195.0,-195.0,-205.0,-205.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["sat_desk_office_sad_paint","","","screen_sat_laugh_went_feet"],"x":[0.8134907604160901,0.8641608076527317,0.8641608076527317,0.0],"xaxis":"x","y":[-200.0,-200.0,-215.0,-215.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["swan_child_young_tall_hands","","","sat_desk_office_children_went"],"x":[0.814449685129116,0.9987083701427203,0.9987083701427203,0.8641608076527317],"xaxis":"x","y":[-180.0,-180.0,-207.5,-207.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["sun_bowl_shone_pure_clean","","","sat_laugh_children_sad_swan"],"x":[0.9859118874944177,1.1815892080100063,1.1815892080100063,0.9987083701427203],"xaxis":"x","y":[-150.0,-150.0,-193.75,-193.75],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["words_sweet_better_lost_work","","","words_times_office_takes_strong"],"x":[0.0,0.6649957751933764,0.6649957751933764,0.0],"xaxis":"x","y":[-225.0,-225.0,-235.0,-235.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["times_lines_drifts_dirt_road","","","feet_brought_moved_day_big"],"x":[0.0,0.9065565358115197,0.9065565358115197,0.0],"xaxis":"x","y":[-245.0,-245.0,-255.0,-255.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["fly_bring_gives_turn_waste","","","cold_north_start_fly_bring"],"x":[0.0,0.6919004811686159,0.6919004811686159,0.0],"xaxis":"x","y":[-265.0,-265.0,-275.0,-275.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["road_times_lines_feet_drifts","","","bring_fly_north_cold_gives"],"x":[0.9065565358115197,1.06180553735437,1.06180553735437,0.6919004811686159],"xaxis":"x","y":[-250.0,-250.0,-270.0,-270.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["smell_stain_odor_hands_burned","","","tender_odor_dirt_cloth_water"],"x":[0.0,0.7374319673825924,0.7374319673825924,0.0],"xaxis":"x","y":[-285.0,-285.0,-295.0,-295.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["bring_fly_north_road_cold","","","odor_cloth_smell_tender_stain"],"x":[1.06180553735437,1.0863956323560813,1.0863956323560813,0.7374319673825924],"xaxis":"x","y":[-260.0,-260.0,-290.0,-290.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["words_times_office_sweet_better","","","bring_fly_odor_north_dirt"],"x":[0.6649957751933764,1.1872358914563281,1.1872358914563281,1.0863956323560813],"xaxis":"x","y":[-230.0,-230.0,-275.0,-275.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["sat_sun_sad_shone_swan","","","bring_words_fly_north_dirt"],"x":[1.1815892080100063,1.2649956529077688,1.2649956529077688,1.1872358914563281],"xaxis":"x","y":[-171.875,-171.875,-252.5,-252.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["rare_served_far_bowl_bell","","","tea_served_pot_brown_"],"x":[0.0,0.7094843045528112,0.7094843045528112,0.0],"xaxis":"x","y":[-305.0,-305.0,-315.0,-315.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(133,20,75)"},"mode":"lines","text":["gave_contents_form_pot_girl","","","tall_horse_cup_contents_soft"],"x":[0.0,0.8181142629667506,0.8181142629667506,0.0],"xaxis":"x","y":[-325.0,-325.0,-335.0,-335.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["served_tea_rare_pot_far","","","contents_tall_horse_gave_cup"],"x":[0.7094843045528112,1.0495078838442735,1.0495078838442735,0.8181142629667506],"xaxis":"x","y":[-310.0,-310.0,-330.0,-330.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,220,0)"},"mode":"lines","text":["contents_lawn_went_waste_tree","","","sound_leaves_grass_turn_pipe"],"x":[0.0,0.7689551221773785,0.7689551221773785,0.0],"xaxis":"x","y":[-345.0,-345.0,-355.0,-355.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,220,0)"},"mode":"lines","text":["leaves_pipe_brown_sound_grass","","","pipe_spring_tell_ran_mark"],"x":[0.7689551221773785,0.856732692317727,0.856732692317727,0.0],"xaxis":"x","y":[-350.0,-350.0,-365.0,-365.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["contents_served_pot_tea_horse","","","pipe_leaves_brown_sound_grass"],"x":[1.0495078838442735,1.1525581872019428,1.1525581872019428,0.856732692317727],"xaxis":"x","y":[-320.0,-320.0,-357.5,-357.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["bring_times_sat_sun_words","","","pipe_contents_brown_leaves_served"],"x":[1.2649956529077688,1.3179987267290945,1.3179987267290945,1.1525581872019428],"xaxis":"x","y":[-212.1875,-212.1875,-338.75,-338.75],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["pack_seven_tried_write_right","","","bring_shone_times_dirt_bowl"],"x":[1.1775474869666154,1.3537981723782502,1.3537981723782502,1.3179987267290945],"xaxis":"x","y":[-54.375,-54.375,-275.46875,-275.46875],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["spring_tender_need_food_drink","","","door_food_needed_bad_red"],"x":[0.0,0.740508213317787,0.740508213317787,0.0],"xaxis":"x","y":[-385.0,-385.0,-395.0,-395.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(40,35,35)"},"mode":"lines","text":["food_drink_cup_covered_sweet","","","food_door_spring_needed_tender"],"x":[0.0,0.7711156254585024,0.7711156254585024,0.740508213317787],"xaxis":"x","y":[-375.0,-375.0,-390.0,-390.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["fence_square_spot_straw_long","","","tight_straw_covered_tell_door"],"x":[0.0,0.7231750933416261,0.7231750933416261,0.0],"xaxis":"x","y":[-405.0,-405.0,-415.0,-415.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["paint_lines_covered_edge_corner","","","straw_screen_near_lawn_gives"],"x":[0.0,0.8500367348109352,0.8500367348109352,0.0],"xaxis":"x","y":[-425.0,-425.0,-435.0,-435.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["straw_tight_door_fence_square","","","corner_paint_coat_gives_near"],"x":[0.7231750933416261,0.9965235211146807,0.9965235211146807,0.8500367348109352],"xaxis":"x","y":[-410.0,-410.0,-430.0,-430.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["food_drink_door_spring_needed","","","straw_covered_paint_corner_coat"],"x":[0.7711156254585024,1.15563826110801,1.15563826110801,0.9965235211146807],"xaxis":"x","y":[-382.5,-382.5,-420.0,-420.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["pink_soft_small_used_blue","","","drifts_seen_pink_north_stood"],"x":[0.0,0.7207342973548572,0.7207342973548572,0.0],"xaxis":"x","y":[-455.0,-455.0,-465.0,-465.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["air_tree_pink_near_drifts","","","pink_soft_seen_drifts_north"],"x":[0.0,0.7409513145001888,0.7409513145001888,0.7207342973548572],"xaxis":"x","y":[-445.0,-445.0,-460.0,-460.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["ship_lost_port_torn_big","","","port_taste_hold_water_strong"],"x":[0.0,0.7779287117932933,0.7779287117932933,0.0],"xaxis":"x","y":[-475.0,-475.0,-485.0,-485.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["dried_stain_spot_wet_lead","","","taste_cut_tree_served_sent"],"x":[0.0,0.8463729761338102,0.8463729761338102,0.0],"xaxis":"x","y":[-505.0,-505.0,-515.0,-515.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(61,153,112)"},"mode":"lines","text":["low_beat_lead_end_kept","","","taste_cut_tree_served_knife"],"x":[0.0,0.925059800311652,0.925059800311652,0.8463729761338102],"xaxis":"x","y":[-495.0,-495.0,-510.0,-510.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["house_dried_heavy_gives_torn","","","hung_work_carved_quite_knife"],"x":[0.0,0.7459985275898569,0.7459985275898569,0.0],"xaxis":"x","y":[-525.0,-525.0,-535.0,-535.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(255,65,54)"},"mode":"lines","text":["torn_carved_hold_house_work","","","box_square_seen_wooden_paper"],"x":[0.7459985275898569,0.9195181161476698,0.9195181161476698,0.0],"xaxis":"x","y":[-530.0,-530.0,-545.0,-545.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["lead_beat_taste_low_cut","","","carved_torn_seen_box_hold"],"x":[0.925059800311652,1.0194229972274573,1.0194229972274573,0.9195181161476698],"xaxis":"x","y":[-502.5,-502.5,-537.5,-537.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["ship_port_lost_torn_taste","","","dried_carved_torn_seen_lead"],"x":[0.7779287117932933,1.0837424198268861,1.0837424198268861,1.0194229972274573],"xaxis":"x","y":[-480.0,-480.0,-520.0,-520.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["slide_straight_open_wooden_near","","","line_serve_clean_needs_straight"],"x":[0.0,0.71571540858521,0.71571540858521,0.0],"xaxis":"x","y":[-555.0,-555.0,-565.0,-565.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(35,205,205)"},"mode":"lines","text":["line_straight_slide_left_knife","","","win_line_lead_heavy_crack"],"x":[0.71571540858521,0.8169252198361677,0.8169252198361677,0.0],"xaxis":"x","y":[-560.0,-560.0,-575.0,-575.0],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["torn_taste_hold_ship_seen","","","line_crack_straight_slide_left"],"x":[1.0837424198268861,1.1580476751907902,1.1580476751907902,0.8169252198361677],"xaxis":"x","y":[-500.0,-500.0,-567.5,-567.5],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["pink_drifts_soft_edge_air","","","hold_lead_torn_port_knife"],"x":[0.7409513145001888,1.2897005048351293,1.2897005048351293,1.1580476751907902],"xaxis":"x","y":[-452.5,-452.5,-533.75,-533.75],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["door_covered_food_straw_drink","","","hold_torn_line_lead_seen"],"x":[1.15563826110801,1.3971450814373279,1.3971450814373279,1.2897005048351293],"xaxis":"x","y":[-401.25,-401.25,-493.125,-493.125],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","marker":{"color":"rgb(0,116,217)"},"mode":"lines","text":["start_great_fast_better_bring","","","hold_door_port_food_near"],"x":[1.3537981723782502,1.4473924626414951,1.4473924626414951,1.3971450814373279],"xaxis":"x","y":[-164.921875,-164.921875,-447.1875,-447.1875],"yaxis":"y","type":"scatter"},{"hoverinfo":"text","hovertext":["china_bank_win_poor_loud","cause_bad_don_right_need","quite_week_home_tried_long","tried_right_week_tales_cause","pack_china_come_bank_neat","clean_brass_shone_pure_neat","sat_desk_office_sad_paint","swan_child_young_tall_hands","sun_bowl_shone_pure_clean","road_times_lines_feet_drifts","bring_fly_north_road_cold","words_times_office_sweet_better","sat_sun_sad_shone_swan","served_tea_rare_pot_far","leaves_pipe_brown_sound_grass","contents_served_pot_tea_horse","bring_times_sat_sun_words","pack_seven_tried_write_right","straw_tight_door_fence_square","food_drink_door_spring_needed","torn_carved_hold_house_work","lead_beat_taste_low_cut","ship_port_lost_torn_taste","line_straight_slide_left_knife","torn_taste_hold_ship_seen","pink_drifts_soft_edge_air","door_covered_food_straw_drink","start_great_fast_better_bring"],"marker":{"color":"black"},"mode":"markers","showlegend":false,"x":[0.7023981972464493,0.7347509556316418,0.7443195760036879,1.070598179334618,1.0755840455610057,0.8560031770216168,0.8134907604160901,0.814449685129116,0.9859118874944177,0.9065565358115197,1.06180553735437,0.6649957751933764,1.1815892080100063,0.7094843045528112,0.7689551221773785,1.0495078838442735,1.2649956529077688,1.1775474869666154,0.7231750933416261,0.7711156254585024,0.7459985275898569,0.925059800311652,0.7779287117932933,0.71571540858521,1.0837424198268861,0.7409513145001888,1.15563826110801,1.3537981723782502],"y":[-10.0,-70.0,-50.0,-65.0,-20.0,-140.0,-200.0,-180.0,-150.0,-250.0,-260.0,-230.0,-171.875,-310.0,-350.0,-320.0,-212.1875,-54.375,-410.0,-382.5,-530.0,-502.5,-480.0,-560.0,-500.0,-452.5,-401.25,-164.921875],"type":"scatter"},{"hoverinfo":"text","hovertext":["pack_come_bell_office_neat","men_act_tell_saw_right","right_tales_cause_tried_men","seven_base_add_help_great","seven_base_finish_add_write","seven_tried_write_right_act","sun_bowl_ice_cold_came","sat_desk_office_children_went","sat_laugh_children_sad_swan","bring_fly_north_cold_gives","odor_cloth_smell_tender_stain","bring_fly_odor_north_dirt","bring_words_fly_north_dirt","contents_tall_horse_gave_cup","pipe_leaves_brown_sound_grass","pipe_contents_brown_leaves_served","bring_shone_times_dirt_bowl","food_door_spring_needed_tender","corner_paint_coat_gives_near","straw_covered_paint_corner_coat","pink_soft_seen_drifts_north","taste_cut_tree_served_knife","carved_torn_seen_box_hold","dried_carved_torn_seen_lead","line_crack_straight_slide_left","hold_lead_torn_port_knife","hold_torn_line_lead_seen","hold_door_port_food_near"],"marker":{"color":"black"},"mode":"markers","showlegend":false,"x":[0.8302524002939504,0.8828279977919145,0.9781284104581118,0.72054931339644,0.8416384866044375,1.1374289569926395,0.7771584036934067,0.8641608076527317,0.9987083701427203,0.6919004811686159,0.7374319673825924,1.0863956323560813,1.1872358914563281,0.8181142629667506,0.856732692317727,1.1525581872019428,1.3179987267290945,0.740508213317787,0.8500367348109352,0.9965235211146807,0.7207342973548572,0.8463729761338102,0.9195181161476698,1.0194229972274573,0.8169252198361677,1.1580476751907902,1.2897005048351293,1.3971450814373279],"y":[-30.0,-90.0,-80.0,-120.0,-112.5,-88.75,-160.0,-207.5,-193.75,-270.0,-290.0,-275.0,-252.5,-330.0,-357.5,-338.75,-275.46875,-390.0,-430.0,-420.0,-460.0,-510.0,-537.5,-520.0,-567.5,-533.75,-493.125,-447.1875],"type":"scatter"}],                        {"autosize":false,"height":1070,"hovermode":"closest","showlegend":false,"width":1000,"xaxis":{"mirror":"allticks","rangemode":"tozero","showgrid":false,"showline":true,"showticklabels":true,"ticks":"outside","type":"linear","zeroline":false},"yaxis":{"mirror":"allticks","rangemode":"tozero","showgrid":false,"showline":true,"showticklabels":true,"tickmode":"array","ticks":"outside","ticktext":["45_loud_china_street","40_win_poor_china","29_pack_office_neat","37_come_bell_salt","19_week_tried_quite","13_home_week_quite","18_don_cause_turn","23_right_tried_drop","3_men_act_neat","1_saw_dog_child","24_write_seven_open","5_add_help_base","28_long_lines_seven","32_pure_neat_clean","50_brass_shone_clean","47_sun_shone_bowl","51_ice_cold_pure","6_child_hands_far","38_times_swan_sad","20_desk_sat_sad","49_sat_fast_rose","11_screen_sat_laugh","42_words_sweet_better","43_words_times_office","34_times_lines_drifts","30_feet_brought_moved","22_fly_bring_gives","41_cold_north_start","48_smell_stain_odor","35_tender_odor_dirt","17_rare_served_far","55_tea_served_pot","52_gave_contents_form","25_tall_horse_cup","8_contents_lawn_went","12_sound_leaves_grass","33_pipe_spring_tell","57_food_drink_cup","14_spring_tender_need","54_door_food_needed","46_fence_square_spot","27_tight_straw_covered","53_paint_lines_covered","7_straw_screen_near","10_air_tree_pink","31_pink_soft_small","15_drifts_seen_pink","36_ship_lost_port","44_port_taste_hold","26_low_beat_lead","16_dried_stain_spot","9_taste_cut_tree","4_house_dried_heavy","2_hung_work_carved","56_box_square_seen","0_slide_straight_open","39_line_serve_clean","21_win_line_lead"],"tickvals":[-5.0,-15.0,-25.0,-35.0,-45.0,-55.0,-65.0,-75.0,-85.0,-95.0,-105.0,-115.0,-125.0,-135.0,-145.0,-155.0,-165.0,-175.0,-185.0,-195.0,-205.0,-215.0,-225.0,-235.0,-245.0,-255.0,-265.0,-275.0,-285.0,-295.0,-305.0,-315.0,-325.0,-335.0,-345.0,-355.0,-365.0,-375.0,-385.0,-395.0,-405.0,-415.0,-425.0,-435.0,-445.0,-455.0,-465.0,-475.0,-485.0,-495.0,-505.0,-515.0,-525.0,-535.0,-545.0,-555.0,-565.0,-575.0],"type":"linear","zeroline":false,"range":[-580.0,0.0]},"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"font":{"size":22,"color":"Black"},"text":"\u003cb\u003eHierarchical Clustering\u003c\u002fb\u003e","x":0.5,"xanchor":"center","yanchor":"top"},"hoverlabel":{"font":{"size":16,"family":"Rockwell"},"bgcolor":"white"},"plot_bgcolor":"#ECEFF1"},                        {"responsive": true}                    )                };                            </script>
</div>
<p>The hierarchical structure is based on how topics emerge based on the
similarity of their embeddings, however, we can often find topics that
we think should be merged based on our own knowledge. For example,
despite their embeddings having a relatively large distance between
them, topic 2 and 14 both appear to be about food.</p>
</div>
<div class="section level4">
<h4 id="looking-at-topic-contents">Looking at Topic Contents<a class="anchor" aria-label="anchor" href="#looking-at-topic-contents"></a>
</h4>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">topic_representations</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">Topic</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">14</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;   Topic Count                       Name</span></span>
<span><span class="co">#&gt; 1     2    20   2_hung_work_carved_quite</span></span>
<span><span class="co">#&gt; 2    14    13 14_spring_tender_need_food</span></span>
<span><span class="co">#&gt;                                                        Representation</span></span>
<span><span class="co">#&gt; 1   hung, work, carved, quite, knife, torn, seen, little, hold, needs</span></span>
<span><span class="co">#&gt; 2 spring, tender, need, food, drink, needed, came, horse, road, grass</span></span>
<span><span class="co">#&gt;                                                    keybert</span></span>
<span><span class="co">#&gt; 1 carved_hung_brass_hold_knife_quite_bright_coat_fine_work</span></span>
<span><span class="co">#&gt; 2   grass_drink_horse_road_food_tender_way_man_spring_need</span></span>
<span><span class="co">#&gt;                                                          mmr</span></span>
<span><span class="co">#&gt; 1   knife_carved_little_needs_work_quite_torn_seen_hold_hung</span></span>
<span><span class="co">#&gt; 2 grass_horse_needed_road_need_food_tender_came_drink_spring</span></span>
<span><span class="co">#&gt;                                    flanT5</span></span>
<span><span class="co">#&gt; 1                      carved wooden work</span></span>
<span><span class="co">#&gt; 2 horse came in spring for food and drink</span></span></code></pre></div>
<p>For larger topics we might need to use more sophisticated language
analysis tools, but since these topics are relatively small, we can just
examine exemplars.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">topic</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">14</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">sentence</span>, <span class="va">topic</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 33 × 2</span></span></span>
<span><span class="co">#&gt;    sentence                                      topic</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>                                         <span style="color: #949494; font-style: italic;">&lt;int&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> the hogs were fed chopped corn and garbage.      14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> the pearl was worn in a thin silver ring.         2</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> a tusk is used to make costly gifts.              2</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> hemp is a weed found in parts of the tropics.    14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> she sewed the torn coat quite neatly.             2</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> she has a smart way of wearing clothes.           2</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> farmers came in to thresh the oat crop.          14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> coax a young calf to drink from a bucket.        14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> madam, this is the best brand of corn.           14</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> the gold ring fits only a pierced ear.            2</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># ℹ 23 more rows</span></span></span></code></pre></div>
<p>I am pretty happy that these two topics could be merged into a larger
“food” topic, to do this we use the bt_merge_topics function:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bt_merge_topics.html">bt_merge_topics</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                topics_to_merge <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">14</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Topics merged &amp; input model updated accordingly</span></span></code></pre></div>
<p>We have been maintaining a dataframe all along that is tracking each
step we’ve completed, it would be good to now update that dataframe with
our new topics.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>merged_topics <span class="op">=</span> <span class="va">topic_model</span><span class="op">$</span><span class="va">topics_</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="reducing-outliers">Reducing Outliers<a class="anchor" aria-label="anchor" href="#reducing-outliers"></a>
</h3>
<p>One feature of hdbscan is the outlier category, which can be quite
large. Sometimes we might want to redistribute these outlier documents
so that they fall within one of the existing topics. There are a number
of methods to achieve this and it is good practice to look at different
parameters and different methods when reducing outliers as it can be
quite difficult to redistribute outlier documents while maintaining
clarity within your topics. To this end, you should consider project
goal is before implementing any of these methods, it is more important
to have concise and coherent topics or to force most/all of your
documents into topics, is it a balance of the two?</p>
<p>The methods currently available to us are:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Tokenset Similarity:</strong> Divides each documents into
tokensets and calculates the c-TF-IDF cosine similarity between each
tokenset and each topic. The summation of each cosine similarity score
for each topic across each outlier document gives the most similar topic
for each outlier document.</p></li>
<li><p><strong>Embeddings:</strong> Measures the cosine similarity
between embeddings for each outlier document and each topic. If we have
passed an empty embedding model to bt_compile_model (which we did), we
must specify an embedding model to be used with this function.</p></li>
<li><p><strong>c-TF-IDF:</strong> Calculates the c-TF-IDF cosine
similarity for each outlier document and topic and redistributes
outliers based on the topic with which it has the highest
similarity.</p></li>
</ol>
<p>We can play with all outlier strategies as, unlike when we merge
topics or fit the model, the bt_outlier_* functions do not update the
model, they only output a df with each document, their current topic
classification and the potential new topics. We must update the model
using bt_update_topics to actually change the topics within the
model.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">outliers_ts_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_outliers_tokenset_similarity.html">bt_outliers_tokenset_similarity</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                                   documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                                   topics <span class="op">=</span> <span class="va">topic_model</span><span class="op">$</span><span class="va">topics_</span>,</span>
<span>                                                   threshold <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">outliers_embed</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_outliers_embeddings.html">bt_outliers_embeddings</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                         documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                         topics <span class="op">=</span> <span class="va">topic_model</span><span class="op">$</span><span class="va">topics_</span>,</span>
<span>                                         embeddings <span class="op">=</span> <span class="va">reduced_embeddings</span>,</span>
<span>                                         embedding_model <span class="op">=</span> <span class="va">embedder</span>,</span>
<span>                                         threshold <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">outliers_ctfidf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bt_outliers_ctfidf.html">bt_outliers_ctfidf</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                                      documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                                      topics <span class="op">=</span> <span class="va">topic_model</span><span class="op">$</span><span class="va">topics_</span>,</span>
<span>                                      threshold <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span></code></pre></div>
<p>It would be useful now to look at how each method has redistributed
the outlier topics. The graph below shows how outliers have been
redistributed to topics below topic 12. You can see how each strategy
does not redistribute topics in the same way, the embedding strategy for
example, has found that 6 outlier documents are best represented by
topic 1, while no other strategy has found any outlier documents that
are best represented by topic 1. The embedding method has also
redistributed all outlier documents, while the c-TF-IDF and tokenset
similarity methods have left certain documents as outliers. This is
where playing around with the threshold parameter, to find a good fit
for your data and chosen strategy, is important.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>outliers_ts_sim <span class="op">=</span> <span class="va">outliers_ts_sim</span><span class="op">$</span><span class="va">new_topics</span>,</span>
<span>         outliers_embed <span class="op">=</span> <span class="va">outliers_embed</span><span class="op">$</span><span class="va">new_topics</span>,</span>
<span>         outliers_ctfidf <span class="op">=</span> <span class="va">outliers_ctfidf</span><span class="op">$</span><span class="va">new_topics</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">merged_topics</span> <span class="op">==</span> <span class="op">-</span><span class="fl">1</span>,</span>
<span>         <span class="va">outliers_ctfidf</span> <span class="op">&lt;</span> <span class="fl">12</span>,</span>
<span>         <span class="va">outliers_embed</span> <span class="op">&lt;</span> <span class="fl">12</span>,</span>
<span>         <span class="va">outliers_ts_sim</span> <span class="op">&lt;</span> <span class="fl">12</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">outliers_ts_sim</span>, <span class="va">outliers_embed</span>, <span class="va">outliers_ctfidf</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html" class="external-link">pivot_longer</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/everything.html" class="external-link">everything</a></span><span class="op">(</span><span class="op">)</span>, names_to <span class="op">=</span> <span class="st">"outlier_distribution_strategy"</span>, values_to <span class="op">=</span> <span class="st">"topic"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">topic</span><span class="op">)</span>, fill <span class="op">=</span> <span class="va">outlier_distribution_strategy</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html" class="external-link">geom_bar</a></span><span class="op">(</span>position <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/position_dodge.html" class="external-link">position_dodge2</a></span><span class="op">(</span>preserve <span class="op">=</span> <span class="st">"single"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Numbers"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Count"</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"Number of outliers in each topic after redistribution"</span>,</span>
<span>       fill <span class="op">=</span> <span class="st">"Outlier redistribution strategy"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_colour_discrete.html" class="external-link">scale_fill_discrete</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>outliers_ctfidf <span class="op">=</span> <span class="st">"c-TF-IDF"</span>,</span>
<span>                               outliers_embed <span class="op">=</span> <span class="st">"Embeddings"</span>,</span>
<span>                               outliers_ts_sim <span class="op">=</span> <span class="st">"Tokenset similarity"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="manipulating-the-model_files/figure-html/unnamed-chunk-10-1.png" width="700"></p>
<p>You should take a look at some of the documents which have been
redistributed and the topic which they have been redistributed to before
deciding on the best strategy for your data. Unfortunately, this can be
quite laborious for large amounts of data with many topics.</p>
<p>Once you have settled on a new list of topics that you are happy
with, we can update the dataframe we have been keeping. For example, if
after looking at the data we decided that the Tokenset Similarity method
was the most appropriate:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>new_topics <span class="op">=</span> <span class="va">outliers_ts_sim</span><span class="op">$</span><span class="va">new_topics</span><span class="op">)</span></span>
<span></span>
<span><span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">merged_topics</span> <span class="op">==</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">merged_topics</span>, <span class="va">new_topics</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 162 × 2</span></span></span>
<span><span class="co">#&gt;    merged_topics new_topics</span></span>
<span><span class="co">#&gt;            <span style="color: #949494; font-style: italic;">&lt;int&gt;</span>      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span>            -<span style="color: #BB0000;">1</span>         -<span style="color: #BB0000;">1</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span>            -<span style="color: #BB0000;">1</span>         34</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span>            -<span style="color: #BB0000;">1</span>         41</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span>            -<span style="color: #BB0000;">1</span>         56</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span>            -<span style="color: #BB0000;">1</span>         28</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span>            -<span style="color: #BB0000;">1</span>         51</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span>            -<span style="color: #BB0000;">1</span>         -<span style="color: #BB0000;">1</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span>            -<span style="color: #BB0000;">1</span>         -<span style="color: #BB0000;">1</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span>            -<span style="color: #BB0000;">1</span>         38</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span>            -<span style="color: #BB0000;">1</span>         12</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># ℹ 152 more rows</span></span></span></code></pre></div>
<p>While you can update your model with the new topics, first consider
the future use of your model, if your intention is to use your model to
fit new data, is it better to fit based on the original, more selective
topic classification or the less selective classification that outlier
reduction has resulted in?</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/bt_update_topics.html">bt_update_topics</a></span><span class="op">(</span>fitted_model <span class="op">=</span> <span class="va">topic_model</span>,</span>
<span>                 documents <span class="op">=</span> <span class="va">sentences</span>,</span>
<span>                 new_topics <span class="op">=</span> <span class="va">outliers_ts_sim</span><span class="op">$</span><span class="va">new_topics</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Input model updated</span></span></code></pre></div>
<p>If you would like to have a deeper look at what else we can do using
bertopic, refer to the BertopicR function documentation and the BERTopic
python library, <a href="https://maartengr.github.io/BERTopic/index.html" class="external-link uri">https://maartengr.github.io/BERTopic/index.html</a>.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Jack Penzer, Aoife Ryan.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
