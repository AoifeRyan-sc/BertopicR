% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bt_embed.R
\name{bt_embed}
\alias{bt_embed}
\title{Embed your documents}
\usage{
bt_embed(
  documents,
  ...,
  embedding_model = "all-MiniLM-L6-v2",
  accelerator = "mps",
  progress_bar = TRUE
)
}
\arguments{
\item{documents}{A character vector of the documents to be embedded, e.g. your text variable}

\item{...}{Optional or additional parameters passed to SentenceTransformer's encode function, e.g. batch_size}

\item{embedding_model}{A string containing the name of the SentenceTransformers embedding model}

\item{accelerator}{A string containing the name of a hardware accelerator, e.g. "mps", "cuda". If NULL no acceleartor is used.}

\item{progress_bar}{A logical value indicating whether a progress bar is shown in the console}
}
\value{
An array of floating point numbers
}
\description{
Takes a document, or list of documents, and returns a numerical embedding which can be used as features for machine learning model or for semantic similarity search. If you have pre-computed your embeddings you can skip this step. the bt_embed function is designed to be used as one step in a topic modelling pipeline.
}
\details{
Initially this function is built upon the \code{sentence_transformers} Python library, but it may be expanded to accept other frameworks. You should feed in your documents as a list. You can use hardware accelerators e.g. GPUs, to speed up computation.
}
