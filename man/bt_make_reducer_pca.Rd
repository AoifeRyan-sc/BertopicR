% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/reduce.R
\name{bt_make_reducer_pca}
\alias{bt_make_reducer_pca}
\title{Create pca dimensionality reduction model}
\usage{
bt_make_reducer_pca(
  n_components,
  ...,
  svd_solver = c("auto", "full", "arpack", "randomized")
)
}
\arguments{
\item{n_components}{Number of components to keep}

\item{...}{Sent to sklearn.decomposition.PCA function for adding additional arguments}

\item{svd_solver}{method for reducing components can be auto, full, arpack, randomized}
}
\value{
A PCA Model that can be input to bt_do_reducing to reduce dimensions of data
}
\description{
This function wraps the PCA functionality from Python's sklearn package for
use in R via reticulate. It allows you to perform dimension reduction on
high-dimensional data, its intended use is in a BertopicR pipeline. If you're
concerned about processing time, you most likely will only want to reduce the
dimensions of your dataset once. In this case, when compiling your model with
bt_compile_model you should call \code{reducer <- bt_empty_reducer()}.
}
\examples{
# using default svd_solver
reducer <- bt_make_reducer_pca(n_components = 100)

# speciying extra pca arguments
reducer <- bt_make_reducer_pca (n_components = 20, svd_solver = "full", random_state = 42L)

}
\seealso{
\url{https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html}
\url{https://scikit-learn.org/stable/modules/decomposition.html#pca}
}
