---
title: "Modularising the fit_transform_model function"
author: "Jack Penzer"
date: "2023-06-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

For working out + testing of individual features. Trying to squeeze everything into one function initially appears to make it easier for the user but quickly becomes too inflexible, and too much gets hidden from them (too many implict arguments). The package should be easy to get off the ground with, but also pleasant to use as the user continues/becomes more experienced, i.e. the right abstractions should be made which provide the user with good mental models.

# Load libraries
```{r}
library(BertopicR)
library(dplyr)
library(tidyr)
library(stringr)
```

## bt_embed

```{r}
# BertopicR::import_bertopic()
data <- bert_example_data %>%
  janitor::clean_names() %>%
  filter(!is.na(message), !duplicated(message))

docs <- data %>% head(10) %>% pull(message)

embeddings <- docs %>%
  bt_embed()

docs %>%
  bt_embed(accelerator = "mps")

docs %>%
  bt_embed()

docs <- data %>% pull(message)
```

### Benchmarking CPU vs GPU

```{r}
docs_1k <- bert_example_data %>%
  janitor::clean_names() %>%
  head(1000) %>%
  pull(message)
```

```{r}
cpu_start <- Sys.time()
cpu_embeddings <- docs_1k %>%
  bt_embed(accelerator = "cpu")
(cpu_end <- Sys.time() - cpu_start)
```

```{r}
mps_start <- Sys.time()
mps_embeddings <- docs_1k %>%
  bt_embed(accelerator = "mps") 
(mps_end <- Sys.time() - mps_start)
```

### All docs?

### MPS all - bench

```{r}
library(bench)
embed <- function(documents, batch_size){
  bt_embed(documents = documents, batch_size = batch_size)
}

results <- bench::press(
  batch_size = c(16L, 32L, 64L, 128L, 256L),
  {
    bench::mark(embed(documents = docs, batch_size = batch_size))
  }
)

results %>%
  readr::write_csv("~/Google Drive/My Drive/data_science_project_work/internal_projects/bertopic/experiment_results/mps_batchsize.csv")

ggplot2::autoplot(results)
```

CPU vs MPS
```{r}
accel_embed <- function(documents, accelerator){
  bt_embed(documents = documents, accelerator = accelerator)
}
results_accel <- bench::press(
  bench::mark(accel_embed(documents = docs, accelerator = accelerator), iterations = 5),
  accelerator = c("mps", "cpu", NULL)
)


results_accel %>%
  readr::write_csv("~/Google Drive/My Drive/data_science_project_work/internal_projects/bertopic/experiment_results/accelerator_bt_embed.csv")
ggplot2::autoplot(results_accel)
```


```{r}
mps_all_start <- Sys.time()
mps_all_embeddings <- docs %>%
  bt_embed(accelerator = "mps")
(mps_all_end <- Sys.time() - mps_all_start) #19.6 seconds, 182 batches, looks like it's batch_size = 32L as defualt?
```

```{r}
mps_all_batch_start <- Sys.time()
mps_all_batch_embeddings <- docs %>%
  bt_embed(accelerator = "mps", batch_size = 128L)
(mps_all_batch_end <- Sys.time() - mps_all_batch_start) #25.91 seconds
#128L slower than default
```

```{r}
mps_all_batch64_start <- Sys.time()
mps_all_batch64_embeddings <- docs %>%
  bt_embed(accelerator = "mps", batch_size = 64L)
(mps_all_batch64_end <- Sys.time() - mps_all_batch64_start) #31.2 seconds
```


```{r}
mps_all_batch268_start <- Sys.time()
mps_all_batch268_embeddings <- docs %>%
  bt_embed(accelerator = "mps", batch_size = 256L)
(mps_all_batch268_end <- Sys.time() - mps_all_batch268_start) #25.03366 secs
```


### CPU All
```{r}
cpu_all_start <- Sys.time()
cpu_all_embeddings <- docs %>%
  bt_embed(accelerator = "cpu")
(cpu_all_end <- Sys.time() - cpu_all_start) # 1:59 in fact*
```

### CPU ALL BATCH
```{r}
cpu_all_batch_16_start <- Sys.time()
cpu_all_batch_16_embeddings <- docs %>%
  bt_embed(accelerator = "cpu", batch_size = 16L)
(cpu_all_batch_16_end <- Sys.time() - cpu_all_batch_16_start)

cpu_all_batch_16_end - cpu_all_end #2:06, no faster
```

Use bench::mark and bench::press to benchmark the results

## bt_make_embedder
```{r}
embedder <- bt_make_embedder("all-minilm-l6-v2")
attributes(embedder)
attr(embedder, "embedding_model") <- NULL
attributes(embedder)
```

## bt_do_embedding
```{r}
embeddings <- bt_do_embedding(
  embedder,
  "text"
) 
attributes(embeddings)
```


```{r}
attr(embedder, "embedding_model") <- NULL
attributes(embedder)

embeddings <- bt_do_embedding(
  embedder,
  "text"
) 
attributes(embeddings)

```


## bt_reducer
```{r}
docs <- data %>% head(10) %>% pull(message)
embeddings <- docs %>%
  bt_embed()

reduced_embeddings <- embeddings %>%
  bt_reducer(return_value = "reduced_embeddings")
reduced_embeddings$reduced_embeddings
reduced_embeddings$base_reducer
```

```{r}
embeddings_df <- embeddings %>% as.data.frame()
reduced_embeddings <- bt_reducer(embeddings, verbose = FALSE, return_value = "reduced_embeddings")

#Parameters
n_neighbors = 15L;n_components = 5L; min_dist = 0.0; metric = "euclidean"; random_state = 42L; verbose = FALSE

umap <- reticulate::import("umap")
#Test outside of function
reducer <- umap$UMAP(n_neighbors = n_neighbors,
                     n_components = n_components,
                     min_dist = min_dist,
                     metric = metric,
                     random_state = random_state,
                     verbose = verbose)

#Fit a model
fitted_model <- reducer$fit(embeddings)

#Get embeddings from fitted model
fitted_model$embedding_

not_transformed <- reducer$fit(embeddings)
transformed <- reducer$fit_transform(embeddings)

not_transformed$transform(embeddings)
```


# RStudio example for py classes
```{r}
library(reticulate)
Hi <- PyClass("Hi", list(
  name = NULL,
  `__init__` = function(self, name) {
    self$name <- name
    NULL
  },
  say_hi = function(self) {
    paste0("Hi ", self$name)
  }
))

a <- Hi("World")
a$name <- "Jack"
a$say_hi()
```


## Creating the BaseDimensionalityReduction Class
```{r}
empty_reduction_model <- py$bertopic$dimensionality$BaseDimensionalityReduction()

base_dim <- reticulate::PyClass("BaseDimensionalityReduction", 
                    defs = list(
                      fit = function(self, X){
                        return(self)
                      },
                      transform = function(self, X){
                        return(X)
                        }
                        )
                    )
base_dim$fit("x")
base_dim$transform(X = "Hello")
```

# Testing bt_embed, bt_reducer and fit_transform on some real data
```{r}
library(BertopicR)
library(dplyr)
data <- bert_example_data %>%
  janitor::clean_names() %>%
  filter(!duplicated(message))

embeddings <- bt_embed(data$message)

reducer <- bt_reducer(
  embeddings = embeddings, return_value = "reduced_embeddings", 
  n_components = 10L,
  n_neighbors = 10L,
  min_dist = 0.0001,
  metric = "euclidean", 
  random_state = 18L
)

base_model <- reducer$base_reducer
reduced_embeddings <- reducer$reduced_embeddings
base_model
base_model$fit(1)

library(reticulate)
BertopicR::import_bertopic()

# Fit BERTopic without actually performing any dimensionality reduction
empty_dimensionality_model = BaseDimensionalityReduction()
topic_model = BERTopic(umap_model=empty_dimensionality_model)

topics <- bt_fit_transform_model(cleaned_text = data$message, calculated_embeddings = reduced_embeddings, reducer = base_model, stopwords =  FALSE)

topics_min_size <-  bt_fit_transform_model(cleaned_text = data$message[1:100], calculated_embeddings = reduced_embeddings[1:100, ], reducer = base_model, stopwords =  FALSE, min_topic_size = 5L)
```

It works with the BaseDimensionalityReduction object from Bertopic
```{r}
py_run_string("from bertopic.dimensionality import BaseDimensionalityReduction")
bert_base_dim <- py$BaseDimensionalityReduction
model <- bt_fit_transform_model(cleaned_text = data$message[1:10], calculated_embeddings = reduced_embeddings[1:10,], reducer = bert_base_dim, stopwords =  FALSE)

model$approximate_distribution(data$message[1:10])
```

But not with my implementation
```{r}
reducer <- bt_reducer(
  embeddings = embeddings[1:10, ], return_value = "reduced_embeddings", 
  n_components = 5L,
  n_neighbors = 5L,
  min_dist = 0.0001,
  metric = "euclidean", 
  random_state = 18L
)

base_model <- reducer$base_reducer
reduced_embeddings <- reducer$reduced_embeddings

topics <- bt_fit_transform_model(cleaned_text = data$message[1:10], calculated_embeddings = reduced_embeddings[1:10,], reducer = base_model, stopwords =  FALSE)


bert_base_dim$fit("hello")
bert_base_dim$transform(self = bert_base_dim, X = "why?")

base_model$transform(self = base_model, X = "why?")
base_model$fit(self =base_model, X = "hello")


bert_base_dim$transform(X = "why?")
base_model$transform(X = 1)

?bert_base_dim$fit
```

```{r}
base_model_two <- base_dimensionality_reduction()
base_dimensionality_reduction()

bt_fit_transform_model(cleaned_text = data$message[1:10], calculated_embeddings = reduced_embeddings[1:10,], reducer = base_model_two, stopwords =  FALSE)
```

Quick benchmark: 
Obvs totally unfair as you should include the calculating of the embeddings for the first modular approach, but that makes it pretty complicated (more complicated than it needs to be), the point is to test what happens when we make a change
```{r}
monolithic <- bench::mark(
  bt_fit_transform_model(cleaned_text = data$message)
)

embeddings <- bt_embed(data$message)
reduced <- bt_reducer(embeddings)
reducer <- reduced$base_reducer
reduced_embeddings <- reduced$reduced_embeddings

modular <- bench::mark(
  bt_fit_transform_model(cleaned_text = data$message, calculated_embeddings = reduced_embeddings, 
                         reducer = reducer)
)

modular_change <- bench::mark(
  bt_fit_transform_model(cleaned_text = data$message, calculated_embeddings = reduced_embeddings, 
                         reducer = reducer, min_topic_size = 5L)
)
modular_change

monolithic_five <- bench::mark(
  bt_fit_transform_model(cleaned_text = data$message, min_topic_size = 5L)
)
monolithic_five

results_df <- rbind(monolithic, modular, modular_change, monolithic_five) %>%
  mutate(desc = c("monolith", "modular", "modular_5L", "monolith_5L"), .before = 1)

results_df %>%
  readr::write_csv("~/Google Drive/My Drive/data_science_project_work/internal_projects/bertopic/experiment_results/monolithic_vs_modular.csv")
```

#bt_cluster
```{r}
inspect <- reticulate::import("inspect")

hdbscan <- reticulate::import("hdbscan")

#Make an hdbscan model
spe_hdbscan <- bt_make_clusterer_hdbscan(min_cluster_size = 5L, metric = "euclidean", cluster_selection_method = "eom", prediction_data = FALSE)

#Check args are altering object
hdbscan$max_cluster_size

#Check args
inspect$signature(hdbscan$HDBSCAN)

#Make an HDBScan model with bt_make_clusterer()
gen_hdbscan <- bt_make_clusterer(clustering_method = 'hdbscan')
gen_hdbscan$min_cluster_size == 10

gen_15_hdbscan <- bt_make_clusterer(clustering_method = "hdbscan",min_cluster_size = 15L)
gen_15_hdbscan$min_cluster_size == 15
gen_15_hdbscan$allow_single_cluster

gen_15_error <- bt_make_clusterer(clustering_method = "hdbscan",
                                  min_cluster_size = 15L, allow_single_cluster = TRUE)
gen_15_error$allow_single_cluster

names(gen_15_hdbscan)

hdbscan <- reticulate::import("hdbscan")

#Instantiate an empty model to check the args
empty_model <- hdbscan$HDBSCAN()

#Make a list to imitate dots
dots <- list(min_cluster_size = 10L, metric = "euclidean", alpho = 1.5)
#Check all dots inside the model's arguments
all(names(dots) %in% names(empty_model))

dots[!names(dots) %in% names(empty_model)]

#Store the bad arguments
bad_args <- dots[!names(dots) %in% names(empty_model)]

#Check which args are not valid
names(dots)[!names(dots) %in% names(empty_model)]


#check that every item in dots is a valid argument for a hdbscan model
if(!all(names(dots)) %in% names(empty_model)){
  bad_args <- names(dots)[!names(dots) %in% names(empty_model)]

  stop(paste0("Found bad arguments in hdbscan instantiation: ", bad_args))
}

#Generate a bad call
bad_call <- bt_make_clusterer_hdbscan(alpha = 1.2, min_cluster_size = 20L, metric = "euclidean", min_samples = 5L)

bad_call <- bt_make_clusterer(clustering_method = "hdbscan", alpho = 1.2, min_cluster_size = 20L, metric = "euclidean", min_samples = 5L)

good_call <- bt_make_clusterer_hdbscan(alpha = 1.2, min_cluster_size = 20L, metric = "euclidean", min_samples = 5L)

#Check args
inspect <- reticulate::import("inspect")
inspect$signature(hdbscan$HDBSCAN)


clustering_model <- bt_make_clusterer(n_clusters = 12L, clustering_method = "kmeans")
clustering_model$n_clusters
kmeans <- bt_make_clusterer_kmeans(n_clusters = 5L)
kmeans$n_clusters

```

```{r}
hdbscan <- bt_make_clusterer(clustering_method = "hdbscan")
agglomerative <- bt_make_clusterer(clustering_method = "agglomerative", n_clusters = 2L)
kmeans <- bt_make_clusterer(clustering_method = "kmeans",n_clusters = 2L)

sort(names(hdbscan))
sort(names(agglomerative))
sort(names(kmeans))


models <- list(hdbscan = hdbscan,
     agglomerative = agglomerative,
     kmeans = kmeans)

purrr::map(models, class)

purrr::map(models, names)

embeddings <- array(runif(2000), dim = c(10, 200))

km_clusters <- bt_do_clustering(kmeans, embeddings)
hd_clusters <- bt_do_clustering(hdbscan, embeddings)
ag_clusters <- bt_do_clustering(agglomerative, embeddings)

km_clusters$labels_
hd_clusters$labels_
ag_clusters$labels_

km_clusters$fit_predict()
hd_clusters$fit_predict()
ag_clusters$fit_predict()

intersect(
  intersect(names(kmeans), names(hdbscan)),
            names(agglomerative)
  )

```

## Testing different clustering methods

```{r}
cleaner_text <- bert_example_data %>%
  janitor::clean_names() %>%
  dplyr::filter(!duplicated(message)) %>%
  ParseR::clean_text(message) %>%
  LimpiaR::limpiar_spaces(message) %>%
  LimpiaR::limpiar_duplicates(message)

embedder <- bt_make_embedder("all-mpnet-base-v2")
reducer <- bt_make_reducer(n_neighbors = 10L, min_dist = 0, verbose = FALSE)
py_kmeans <- bt_make_clusterer(clustering_method = "kmeans", n_clusters = 10L)
hdbscan <- bt_make_clusterer_hdbscan(min_cluster_size = 10L, min_samples = 3L)
hdbscan_leaf <- bt_make_clusterer_hdbscan(cluster_selection_method = "leaf", min_samples = 3L)

cleaner_text <- cleaner_text %>%
  dplyr::filter(!message == "")

spam <-cleaner_text %>%
  LimpiaR::limpiar_spam_grams(message, n_gram = 6L, min_freq = 3)

df <- spam$data

texts <- df$message

embeddings <- embedder %>%
  bt_do_embedding(texts)

reduced_embeddings <- reducer %>%
  bt_do_reducing(embeddings = embeddings)

py_kmeans_clusters <- bt_do_clustering(clustering_model = py_kmeans,embeddings = reduced_embeddings)
r_kmeans_clusters <- kmeans(reduced_embeddings, centers = 10L)

r_kmeans_clusters$cluster
py_kmeans_df <- py_kmeans_clusters %>%
  as.data.frame() %>%
  as_tibble() %>%
  rename(py = 1)
r_kmeans_df <- r_kmeans_clusters$cluster %>%
  as.data.frame() %>%
  as_tibble() %>%
  rename(r = 1)

kmeans_df <- bind_cols(py_kmeans_df, r_kmeans_df)

kmeans_df %>%
  count(py, r) %>%
  arrange(desc(n)) %>% 
  as.data.frame()

hdbscan_clusters <- bt_do_clustering(hdbscan, reduced_embeddings)
hdbscan_clusters %>%
  as.data.frame() %>%
  as_tibble() %>%
  rename(clusters = 1) %>%
  count(clusters, sort = TRUE)

leaf_clusters <- bt_do_clustering(hdbscan_leaf, reduced_embeddings)

results <- lapply(unique(leaf_clusters), function(x) sum(x == leaf_clusters))

tibble(cluster = unique(leaf_clusters), results = unlist(results)) %>%
  arrange(desc(results))

  select(message) %>%
  mutate(py_kmeans = py_kmeans_clusters, 
         r_kmeans = r_kmeans_clusters$cluster,
         hdbscan = hdbscan_clusters,
         leafs = leaf_clusters)

clusters_df %>%
  count(leafs, sort = TRUE)

clusters_df %>%
  filter(leafs == 92) %>%
  pull(message)
```


#bt_model
```{r}
model <- bt_compile_model(
  embedding_model <- NULL,
  umap_model <- NULL)
```

#bt_fit
